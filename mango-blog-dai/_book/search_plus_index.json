{"./":{"url":"./","title":"第一部分 基础部分","keywords":"","body":"简介 这是我的第一本使用 GitBook 制作的电子书。 "},"word_explain.html":{"url":"word_explain.html","title":"常用词语解释","keywords":"","body":"常用词语解释 网络中常用的词语 TPS 解释：系统吞吐量 PV(Page View) 页面浏览量或者点击量；用户每一次对网站中的每个网页访问均被记录1次。用户对同一个页面多次访问，访问量累计。 UV(Unique visitor) 是指通过互联网访问、浏览这个网页的自然人。同一个账户在一台电脑上访问为一个方可。 运维常用词语 CI(Continuous Integration) 解释：持续集成 持续集成是指软件个人研发的部分向软件整体部分交付，频繁进行集成以便更快发现其中的错误。 优点： ''快速失败'',在产品没有风险的情况下进行测试，并快速响应。 极大限度地减少风险，降低修复错误代码的成本。 将重复性的手工流程自动化，让工程师更加专注于代码。 保持频繁部署，快速生成可部署的软件 提高项目的能见度，方便团队成员了解项目的进度和成熟度。 CD（Continuous Delivery） 解释：持续交付 持续交付是在持续集成的基础上，将集成后的代码部署到更贴近真实运行环境 持续部署(Continuous Release) 持续部署是指交付的代码通过评审后，自动部署到生产环境中，持续部署是持续交付的最高阶段 QA 解释：测试 OPS 解释：运维 DEV 解释：开发 堡垒机 在一个特定的网络环境下，为了保障网络和数据不受来自外部和内部用户的入侵和破坏，而运用各种技术手段实时收集和监控网络环境中每一个组成部分的系统状态、安全事件、网络活动，以便集中报警、及时处理及审计定责。 从功能上讲，它综合了核心系统运维和安全审计管控两大主干功能 Keystone Keystone(OpenStack Identity Service)是 OpenStack 框架中负责管理身份验证、服务规则和服务令牌功能的模块。也就是身份验证模块。 集群、高并发中的词语 计算机集群架构按照功能和结构可以划分为一下几类 LBC(负载均衡集群，Load balancing clusters) HAC(高可用集群，High-availability clusters) HPC(高性能计算集群，High-perfomance clusters) XFS：高性能日志文件系统 POD：基本操单元，相关的一个或者多个容器构成一个POD，通常不同的POD里的容器运行相同的应用 负载均衡的软件 LVS(linux virtual server) linux虚拟服务器，是一个虚拟的服务器集群系统，可以再unix/linux平台下实现负载均衡集群的功能。 Nginx 作为负载均衡服务器：Nginx 既可以在内部直接支持 Rails 和 PHP 程序对外进行服务，也可以支持作为 HTTP代理服务器对外进行服务。 HAProxy HAProxy是一个使用C语言编写的自由及开放源代码软件[1]，其提供高可用性、负载均衡，以及基于TCP和HTTP的应用程序代理。 云服务相关名词 “云\"其实是互联网的一个隐喻，”云计算“其实就是使用互联网来接入存储或者运行在服务器端的应用、数据、或者服务。 云也是分层的，分别是： Infrastructure(基础设施)-as-a-Service(IaaS)、Platform(平台)-as-a-Service(PaaS)、Software(软件)-as-a-Service(SaaS)。基础设施在最下端，平台在中间，软件在顶端。 IaaS(基础设施即服务) 第一层叫做IaaS，有时候也叫做Hard-as-a-Service,也就是服务器 这一层的作用就是提供虚拟机或者其他资源作为服务提供给用户。 PaaS(平台即服务) 第二层就是PaaS，有时候也叫做中间件。PaaS公司网上提供各种开发和分发应用的解决方案，比如虚拟服务器和操作系统。 这一层的作用是将一个平台作为服务提供给用户 SaaS(软件即服务) 第三层也就是所谓的SaaS。这一层是和我们每一天接触的一层，大多是通过网页浏览器来接入的，任何一个远程服务器上的应用都可以通过网络来运行，就是SaaS。 这一层的作用是将应用作为服务提供给客户。 serverless serverless并不是不需要服务器，而是你无需关注服务。例如，现在你开发一个应用，不需要关心缓存、mq、web容器,在serverless环境下，你只需要关注代码层面的东西，如果需要用mq，只需要调用函数解决，无需关注mq是否能承受压力。 ​ 网络中的名词 ISP(Internet Service Provider) 因特网服务提供商，能提供拨号上网服务、网上浏览、下载文件、收发电子邮件等服务，是网络最终用户进入Internet的入口和桥梁。 ICP（Internet Content Provider） 是互联网内容提供商,向广大用户综合提供互联网信息业务和增值业务的电信运营商 NIC 网卡 XSRF Cross site request forgery：跨站请求伪造 XSS Cross site scripting：跨站脚本攻击 "},"computer_basic.html":{"url":"computer_basic.html","title":"计算机语言中的基本概念","keywords":"","body":"基本概念 编译与解释 编译是将源程序翻译成可执行的目标代码，翻译与执行是分开的；而解释是对源程序的翻译与执行一次性完成，不生成可存储的目标代码。这只是表象，二者背后的最大区别是：对解释执行而言，程序运行时的控制权在解释器而不在用户程序；对编译执行而言，运行时的控制权在用户程序。 解释具有良好的动态特性和可移植性，比如在解释执行时可以动态改变变量的类型、对程序进行修改以及在程序中插入良好的调试诊断信息等，而将解释器移植到不同的系统上，则程序不用改动就可以在移植了解释器的系统上运行。同时解释器也有很大的缺点，比如执行效率低，占用空间大，因为不仅要给用户程序分配空间，解释器本身也占用了宝贵的系统资源。 编译器是把源程序的每一条语句都编译成机器语言,并保存成二进制文件,这样运行时计算机可以直接以机器语言来运行此程序,速度很快; 解释器则是只在执行程序时,才一条一条的解释成机器语言给计算机来执行,所以运行速度是不如编译后的程序运行的快的。 动态语言和静态语言 动态类型语言：动态类型语言是指在运行期间才去做数据类型检查的语言，也就是说，在用动态类型的语言编程时，永远也不用给任何变量指定数据类型，该语言会在你第一次赋值给变量时，在内部将数据类型记录下来。Python和Ruby就是一种典型的动态类型语言，其他的各种脚本语言如VBScript也多少属于动态类型语言。 静态类型语言：静态类型语言与动态类型语言刚好相反，它的数据类型是在编译其间检查的，也就是说在写程序时要声明所有变量的数据类型，C/C++是静态类型语言的典型代表，其他的静态类型语言还有C#、JAVA等。 强类型定义语言和弱类型定义语言 强类型定义语言：强制数据类型定义的语言。也就是说，一旦一个变量被指定了某个数据类型，如果不经过强制转换，那么它就永远是这个数据类型了。举个例子：如果你定义了一个整型变量a,那么程序根本不可能将a当作字符串类型处理。强类型定义语言是类型安全的语言。 弱类型定义语言：数据类型可以被忽略的语言。它与强类型定义语言相反, 一个变量可以赋不同数据类型的值。 强类型定义语言在速度上可能略逊色于弱类型定义语言，但是强类型定义语言带来的严谨性能够有效的避免许多错误 计算机语言之间的区别 计算机语言 语言类型 擅长的场景 C 编译型语言 操作系统、嵌入式领域、服务器领域( 网络核心设备（路由器，交换机，防火墙） C++ 编译型语言 游戏领域、办公软件、图形处理(PS)、搜索引擎( Google : 汇编与C++，主要为C++)、图形界面层、关系型数据库、浏览器、编译器 PHP 解释型语言 服务端脚本、中小型网站 JAVA 混合(解释、编译) 企业级应用开发、网站平台开发、移动领域、移动android APP开发 Python 解释型语言 Web应用开发、 操作系统管理、服务器运维的自动化脚本、 科学计算、 桌面软件、 服务器软件（网络软件）、机器学习 "},"java/":{"url":"java/","title":"第二部分 Java基础","keywords":"","body":"Java基础见讲解 "},"java/IO/readme.html":{"url":"java/IO/readme.html","title":"1、Java IO","keywords":"","body":"IO nijo "},"java/IO/IO.html":{"url":"java/IO/IO.html","title":"IO","keywords":"","body":"IO流的处理 1. IO的分类？ IO按照POSIX标准可以分为同步IO以及异步IO两种，其中同步IO中最常用的是BIO（Blocking IO）和NIO（Non-Blocking IO）. 同步IO BIO：从程序的角度而言，BIO就是当发起IO的读或者写操作的时候，均为阻塞方式，只有当程序读取到了流或者将流写入之后才会释放资源。（每个连接一个单独的线程） NIO：是基于事件驱动思想的，实现上通常采用Reactor模式，从程序角度而言，当发起IO的读或写操作时，是非阻塞的。当socket有流可读或可写入Socket时，操作系统会相应的通知应用程序进行处理，应用程序在将流读取到缓冲区或写入操作系统。对于网络IO而言，主要有建立连接、流读取以及流写入三种事件。（每个连接共用一个线程） 异步IO AIO:也是基于事件驱动思想，实现上通常采用Proactor模式。从程序角度而言，和NIO不同，当进行读写操作的时候，只需直接调用read或者write方法即可。这两个方法均为异步的，对于读操作而言，当有流可以读取时，操作系统会将可读的流传入read方法的缓冲区，并通知应用程序。对于写操作而言，当操作系统将write方法传递的读写入完毕时，操作系统会主动通知应用程序。 各个使用场景？ BIO方式适用于连接数比较小且固定的架构，JDK1.4之前的唯一选择 NIO方式适用于连接数目多并且比较短的架构，比如聊天服务器 AIO方式适用于连接数目较多并且比较长的架构，比如相册服务器，充分调用OS参与并发操作，jdk1.7之后开始支持。 2. Reactor和Proactor模式 使用场景？ Ractor适用于同步IO Proavtor适用于异步IO Reactor模式 Proactor模式 "},"java/IO/nio_basic.html":{"url":"java/IO/nio_basic.html","title":"NIO基础","keywords":"","body":"1.NIO与IO的区别？ IO NIO 面向流 面向缓冲 阻塞IO 非阻塞IO 无 选择器 2. NIO中的读和写 2.1 从文件中读取 读取文件的三个步骤 从FileInputStream获取channel FileInputStream fin = new FileInputStream(\"readandshow.txt\"); FileChannel fc = fin.getChannel(); 创建Bufffer ByteBuffer buffer = ByteBuffer.allocate(1024); 将数据从channel读取到buffer中 fc.read(buffer); 2.2 写入文件 写入文件的三个步骤 从FileOutputStream获取channel FileOutputStream fout = new FileOutputStream(\"writessomebytes.txt\"); FileChannel fc = fout.getChannel(); 创建缓冲区（Buffer）并且存放对象 ByteBuffer buffer = ByteBuffer.allocate(1024); for(int i=0; i 写入缓冲区 fc.write(buffer); 3 缓冲区的内部细节 NIO中有两个重要的缓冲区组件：状态变量和访问方法。 每一次读/写操作都会改变缓冲区的状态。状态变量通过记录和跟踪这些变化，缓冲区就能够内部地管理自己的资源。 从通道读取数据时，数据被放入缓冲区。在某些情况下，可以将这个缓冲区直接写入另一个通道，但是在一般情况下，您还需要查看数据，使用get()完成。同样，如果要将原始数据放入到缓冲区中，就需要使用put()方法。 3.1 状态变量 可以使用三个值来指定缓冲区在任意时刻的状态： position limit capacity 这三个变量一起可以跟踪缓冲区的状态和它包含的数据。 ​ Position 缓冲区是就上就是美化了数组。在从通道读取时，您将所读的数据放到底层的数组中。position变量跟踪已经写了多少数据。更准确的说，它指定了下一个字节将放到数组的那一个元素中。因此，如果您从通道中读三个字节到缓冲区。那么缓冲区的position将会设置3，指向第四个元素。 Limit limit变量表明还有多少数据需要取出（从缓冲区写入通道中），或者还有多少空间可以放入数据 position Capacity 缓冲区的capacity表明可以存储在缓冲区的最大数据容量。实际上，它指定了底层数组的大小。 limit 缓冲区的使用 使用缓冲区将数据从输入通道拷贝到输出通道 while (true) { buffer.clear(); int r = fcin.read( buffer ); if (r==-1) { break; } buffer.flip(); fcout.write( buffer ); } ​ 4 缓冲区的其他知识点 4.1 缓冲区的分配以及包装 在能够读以及写之前，必须有一个缓冲区。要创建缓冲区，就需要分配缓冲区。分配缓冲区使用的是allocate()来分配缓冲区： ByteBuffer buffer = ByteBuffer.allocate(1024); allocate()方法分配一个具有指定大小的底层数组，并将它包装到一个缓冲区对象中，在上面代码中采用的是ByteBuffer 也可以将现有的数组转换为缓冲区，如下所示： byte array[] = new byte[1024]; ByteBuffer buffer = ByteBuffer.wrap(array); 4.2 缓冲区分片 slice()方法根据现有的缓冲区创建一种子缓冲区。也就是说，它创建一个新的缓冲区，新缓冲区和原来的缓冲区的一部分数据共享，如下所示： 创建一个长度为10的ByteBuffer ByteBuffer buffer = ByteBuffer.allocate(10); 然后使用数据来填充这个缓冲区，在第n个槽中放入数字n: for(int i=0; i 现在对这个缓冲区分片，以创建一个包含3到6的子缓冲区。在某种意义上，子缓冲区就像原来的缓冲区中的一个窗口。窗口的开始和结束位置通过position和limit值来设定，然后调用Buffer的slice()方法： buffer.position(3); buffer.limite(7); ByteBuffer slice = buffer.slice(); 片段是元缓冲区的子缓冲区，并且我们知道缓冲区和子缓冲区共享同一个底层数据数组。 4.3 缓冲区分片和数据共享 缓冲区中的子缓冲区发生了改变之后，缓冲区中对应的子缓冲区所修改的也会相应的修改。 4.4 只读缓冲区 只读缓冲区只能读取，可以通过调用缓冲区的asReadOnlyBuffer()方法，将任何常规缓冲区转换为只读缓冲区。 只读缓冲区对于数据的保护很有用，并且可以保证缓冲区不被修改。 不能将只读缓冲区转换为可写的缓冲区。 4.5 直接和间接缓冲区 另外一种有用的ByteBuffer是直接缓冲区。直接缓冲区是为了加快I/O速度，而已一种特殊的方式分配其内存的缓冲区。 内存映射文件可以创建直接缓冲区。 4.6 内存映射文件I/O 内存映射文件I/O是一种读和写文件数据的方法，它可以比常规的基于流或者基于通道的I/O快得多。 内存映射文件I/O是通过使文件中的数据出现在内存数组来完成的。 4.6 将文件映射到内存 将一个FileChannel(它的全部或者部分)映射到内存中。为此我们将使用FileChannel。map()方法，如下所示： MappedByteBuffer mbb = fc.map(FileChannel.MapMode.READ_WRITE, 0, 1024); 5 连网和异步I/O 5.1 异步I/O 异步I/O是一种没有阻塞的读写数据的方法。异步I/O也不会阻塞。异步I/O允许用户根据大量的输入和输出执行I/O。 5.2 Selectors Selector选择器类管理着一个被注册的通道集合的信息和他们的就绪状态。通道和选择器一起被注册，并且使用选择器来更新通道的就绪状态。当这么做的时候，可以选择将被激发的线程挂起，直到有就绪的状态。 其中异步I/O的核心对象是Selector。 Selector selector = Selector.open(); 之后在对不同的通道对象调用register()方法。以便注册我们对这些对象中发生的I/O事件的兴趣。register()的第一个参数是Selector。 5.3 打开一个ServerSocketChannel 为了接收连接，我们需要一个ServerSocketChannel。加您给一个端口都需要一个ServerSocketChannel。对于每一个端口，我们打开一个ServerSocketChannel，如下所示： ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.configureBlocking( false ); ServerSocket ss = ssc.socket(); InetSocketAddress address = new InetSocketAddress(ports[i]); ss.bind(address); 第一行创建一个新的ServerSocketChannel，最后三行将它绑定到给定的端口。第二行ServerSocketChannel设置为非阻塞的。必须对每一个要使用的套接字通道调用这个方法，否则异步I/O就不能工作。 5.4 选择键 将上面步骤打开的ServerSocketChannels注册到Selector上，为此使用的方法是ServerSocketChannel.register()方法，如下所示： SelectionKey key = ssc.register(selector, SelectortKey.OP_ACCEPT); register()第一个参数总是这个Selector。第二个参数是OP_ACCEPT，这里它指定我们想要监听accept事件，也是在新的连接建立时所发生的事件。这里适用于ServerSocketChannel的唯一事件类型。 SelectionKey代表这个通道在此Selector上的这个注册。当某个Selector通知传入事件的时候，通过提供对该事件的SelectionKey来进行，还可以取消通道注册。 5.5 内部循环 现在已经注册了我们对一些I/O事件，在主循环中，使用Selectors的几乎每个程序都像下面这样使用内部循环： int num = selector.select(); Set selectionKeys = selector.selectedKeys(); Iterator it = selectkeys.iterator(); while(it.hasNext()){ SelectionKey key = (SelectionKey)it.next(); //.. deal with I/O even... } ​ 5.6 监听新的连接 使用SelectionKey调用readOps()方法，并检查发生了什么类型的事件： if(key.readOps() & SelectionKey.OP_ACCEPT == SelectionKey.OP_ACCEPT){ // accept new connection } 6 基本概念 6.1 什么是Selector以及SelectionKey？ Selector（选择器）：是javaNIO中能够检测出一到多个NIO通道，并能够知晓通道是否为诸如读写事件做好准备的组件。这样一个单独的线程可以管理多个channel，从而管理多个网络连接。 SelectionKey： 表示SelectableChannel在Selector中的注册的标记/句柄 ​ "},"java/IO/NIO_TCP.html":{"url":"java/IO/NIO_TCP.html","title":"TCP之NIO连接","keywords":"","body":"1. 服务器端 创建一个Selector实例 将其注册到各种信道， 并指出每个信道上对应的I/O操作 重复执行 调用一种select()方法 获取选取的键的列表 对于已选键集中的每个键 获取信道，并从键中获取附件 确定准备就绪的操纵并执行，如果是accept操作，将接收的信道设置为非阻塞模式，并注册到选择器中。 如果需要，修改键的操作 从已选键集中移除键 2. 客户端 客户端通过信道建立连接 3 代码 客户端代码如下所示： import java.net.InetSocketAddress; import java.net.SocketException; import java.nio.ByteBuffer; import java.nio.channels.SocketChannel; public class TCPEchoClientNonblocking { public static void main(String args[]) throws Exception{ if ((args.length 3)) throw new IllegalArgumentException(\"参数不正确\"); //第一个参数作为要连接的服务端的主机名或IP String server = args[0]; //第二个参数为要发送到服务端的字符串 byte[] argument = args[1].getBytes(); //如果有第三个参数，则作为端口号，如果没有，则端口号设为7 int servPort = (args.length == 3) ? Integer.parseInt(args[2]) : 7; //创建一个信道，并设为非阻塞模式 SocketChannel clntChan = SocketChannel.open(); clntChan.configureBlocking(false); //向服务端发起连接 if (!clntChan.connect(new InetSocketAddress(server, servPort))){ //不断地轮询连接状态，直到完成连接 while (!clntChan.finishConnect()){ //在等待连接的时间里，可以执行其他任务，以充分发挥非阻塞IO的异步特性 //这里为了演示该方法的使用，只是一直打印\".\" System.out.print(\".\"); } } //为了与后面打印的\".\"区别开来，这里输出换行符 System.out.print(\"\\n\"); //分别实例化用来读写的缓冲区 ByteBuffer writeBuf = ByteBuffer.wrap(argument); ByteBuffer readBuf = ByteBuffer.allocate(argument.length); //接收到的总的字节数 int totalBytesRcvd = 0; //每一次调用read（）方法接收到的字节数 int bytesRcvd; //循环执行，直到接收到的字节数与发送的字符串的字节数相等 while (totalBytesRcvd 服务器端代码如下所示; import java.io.IOException; import java.net.InetSocketAddress; import java.nio.channels.SelectionKey; import java.nio.channels.Selector; import java.nio.channels.ServerSocketChannel; import java.util.Iterator; public class TCPServerSelector{ //缓冲区的长度 private static final int BUFSIZE = 256; //select方法等待信道准备好的最长时间 private static final int TIMEOUT = 3000; public static void main(String[] args) throws IOException { if (args.length ...\"); } //创建一个选择器 Selector selector = Selector.open(); for (String arg : args){ //实例化一个信道 ServerSocketChannel listnChannel = ServerSocketChannel.open(); //将该信道绑定到指定端口 listnChannel.socket().bind(new InetSocketAddress(Integer.parseInt(arg))); //配置信道为非阻塞模式 listnChannel.configureBlocking(false); //将选择器注册到各个信道 listnChannel.register(selector, SelectionKey.OP_ACCEPT); } //创建一个实现了协议接口的对象 TCPProtocol protocol = new EchoSelectorProtocol(BUFSIZE); //不断轮询select方法，获取准备好的信道所关联的Key集 while (true){ //一直等待,直至有信道准备好了I/O操作 if (selector.select(TIMEOUT) == 0){ //在等待信道准备的同时，也可以异步地执行其他任务， //这里只是简单地打印\".\" System.out.print(\".\"); continue; } //获取准备好的信道所关联的Key集合的iterator实例 Iterator keyIter = selector.selectedKeys().iterator(); //循环取得集合中的每个键值 while (keyIter.hasNext()){ SelectionKey key = keyIter.next(); //如果服务端信道感兴趣的I/O操作为accept if (key.isAcceptable()){ protocol.handleAccept(key); } //如果客户端信道感兴趣的I/O操作为read if (key.isReadable()){ protocol.handleRead(key); } //如果该键值有效，并且其对应的客户端信道感兴趣的I/O操作为write if (key.isValid() && key.isWritable()) { protocol.handleWrite(key); } //这里需要手动从键集中移除当前的key keyIter.remove(); } } } } ​ "},"java/lambda/readme.html":{"url":"java/lambda/readme.html","title":"2、Lambada","keywords":"","body":""},"java/lambda/lambda_to_use.html":{"url":"java/lambda/lambda_to_use.html","title":"lambda基本用法","keywords":"","body":"1. 基本的语法说明 lambda表达式非常简单，结构类似如下结构 (parameters) -> expression //或者 (parameters) -> { statements; } lambda表达式组成部分 paramaters：类似于方法中的形参列表，这里的参数是函数式接口里面的参数，这里的参数类型可以明确的声明也可以不声明而由JVM隐含的推断1。另外只有一个推断类型的时候可以省略括号。 ->:可以理解为“被用于”的意思 方法体：可以是表达式也可以是代码块，是函数接口里方法的实现。代码块可以返回一个值也可以不返回，这里的代码块等同于方法的方法体。如果是表达式，也可以返回一个值，也可以不返回。 示列的代码： //示例2：接受两个int类型的参数，并返回这两个参数相加的和 (int x,int y)->x+y; //示例2：接受x,y两个参数，该参数的类型由JVM根据上下文推断出来，并返回两个参数的和 (x,y)->x+y; //示例3：接受一个字符串，并将该字符串打印到控制到，不反回结果 (String name)->System.out.println(name); //示例4：接受一个推断类型的参数name，并将该字符串打印到控制台 name->System.out.println(name); //示例5：接受两个String类型参数，并分别输出，不反回 (String name,String sex)->{System.out.println(name);System.out.println(sex)} //示例6：接受一个参数x，并返回该该参数的两倍 x->2*x ​ 2. 方法引用 方法引用是lambda表达式的一个简化写法。所引用的方法其实是lanbda表达式的方法体的实现，其语法结构为： ObjectRef::methodName 左边可以是类名或者实例名，中间是方法的引用符号“::”,右边是相应的方法名。方法引用分为三类： 2.1 静态方法引用 代码如下所示： ```java public class ReferenceTest { public static void main(String[] args) { Converter converter=new Converter() { @Override public Integer convert(String from) { return ReferenceTest.String2Int(from); } }; converter.convert(\"120\"); } @FunctionalInterface interface Converter{ T convert(F from); } static int String2Int(String from) { return Integer.valueOf(from); } } * 方法的调用代码 ```java Converter converter = ReferenceTest::String2Int; converter.convert(\"120\"); 2.2. 实例方法引用 代码如下所示： public class ReferenceTest { public static void main(String[] args) { Converter converter = new Converter() { @Override public Integer convert(String from) { return new Helper().String2Int(from); } }; converter.convert(\"120\"); } @FunctionalInterface interface Converter { T convert(F from); } static class Helper { public int String2Int(String from) { return Integer.valueOf(from); } } } 实例方法的引用如下所示： Helper helper = new Helper(); Converter converter = helper::String2Int; converter.convert(\"120\"); ​ 2.3 构造方法引用 代码如下所示： 首先先定义一个父类Animal: class Animal{ private String name; private int age; public Animal(String name, int age) { this.name = name; this.age = age; } public void behavior(){ } } 接下来定义两个Animal的子类：Dog、Bird public class Bird extends Animal { public Bird(String name, int age) { super(name, age); } @Override public void behavior() { System.out.println(\"fly\"); } } class Dog extends Animal { public Dog(String name, int age) { super(name, age); } @Override public void behavior() { System.out.println(\"run\"); } } 随后定义一个工厂接口： interface Factory { T create(String name, int age); } 接下来用传统的方法来创建Dog类和Bird类的对象： Factory factory=new Factory() { @Override public Animal create(String name, int age) { return new Dog(name,age); } }; factory.create(\"alias\", 3); factory=new Factory() { @Override public Animal create(String name, int age) { return new Bird(name,age); } }; factory.create(\"smook\", 2); 使用构造函数引用来创建： Factory dogFactory =Dog::new; Animal dog = dogFactory.create(\"alias\", 4); Factory birdFactory = Bird::new; Bird bird = birdFactory.create(\"smook\", 3); ​ 3. lambda的域以及访问限制 域即为作用域，Lambda表达式中参数在该lambda表达式范围内有效。在作用lambda表达式内，可以访问外部的变量：局部变量、类变量和静态变量。 3.1 访问局部变量 在lambda表达式外部的局部变量会被JVM隐式的编译成final类型，因此只能访问而不能修改。 public class ReferenceTest { public static void main(String[] args) { int n = 3; Calculate calculate = param -> { //n=10; 编译错误 return n + param; }; calculate.calculate(10); } @FunctionalInterface interface Calculate { int calculate(int value); } } 3.2 访问静态变量和成员变量 在lambda表达式内部，对静态变量和成员变量可读可写。 public class ReferenceTest { public int count = 1; public static int num = 2; public void test() { Calculate calculate = param -> { num = 10;//修改静态变量 count = 3;//修改成员变量 return n + param; }; calculate.calculate(10); } public static void main(String[] args) { } @FunctionalInterface interface Calculate { int calculate(int value); } } ​ 3.3 lambda不能访问函数接口的默认方法 在java8中，接口可以创建默认方法，但是在lambda表达式内部不支持访问默认方法。 "},"java/multi_thread/readme.html":{"url":"java/multi_thread/readme.html","title":"3、多线程","keywords":"","body":""},"java/multi_thread/Disruptor.html":{"url":"java/multi_thread/Disruptor.html","title":"Disruptor","keywords":"","body":"Disrutor的基本概念以及使用 一、 什么是Disruptor？ 从功能上来看，Disruptor是实现了“队列”的功能，而且是一个有界队列。使用的场景为“生产者--消费者”模型的应用场合。 生产者往队列中发布一项消息时，消费者能获得通知，如果没有消息的时候，消费者会被阻塞，直到生产者发布了新的消息。 同一个“事件”可以有多个消费者，消费者之间可以并行的处理，也可相互的依赖形成处理的先后次序。 二、 Disruptor的核心概念 1. RingBuffer 环行的缓冲区。曾经RingBuffer是Disruptor中的主要的对象，在3.0版本之后，其职责被简化为仅仅负责对通过Disruptor进行交换数据（事件）进行存储和更新。 2. Sequence Disruptor 通过顺序递增的序号来编号管理通过其进行交换的数据（事件），对数据（事件）的处理过程总是沿着序号逐个递增处理。一个sequence用于跟踪标识某个特定的事件处理者(RingBuffer/Consumer)的处理进度。并且也防止不同的Sequence之间的cpu缓存伪共享问题。 3. Sequencer Sequencer是Disruptor的真正核心。此接口的两个实现类SingleProducerSequencer、MultiProducerSequencer，他们定义在生产者和消费者之间快速、正确的传递数据的并发算法。 4. Sequence Barrier 用于保持对RingBuffer的main published Sequence和Consumer依赖的其它Consumer的Sequence引用。Sequence Barrier还定义了句顶Consumer是否还有可以处理的事件逻辑。 5. Wait Strategy 定义Consumer如何进行等待下一个事件爱你的策略。（Tips：Disruptor定义了多种不同的策略，针对不同的场景，提供了不一样的性能表现） 6. Event 在disruptor的语义中，生产者和消费者之间进行交换的数据称之为事件（Event）。不是Disruptor定义的特定类型。而是由Disruptor的使用者定义并指定。 7. EventProcessor EventProcessor持有特定消费者的Sequence，并提供用于调用事件处理实现的实践循环。 8. EventHandler Disruptor定义的事件处理接口，由用户实现，用于处理事件，是Consumer的真正实现。 9. producer 生产者，只是泛指调用Disruptor发布事件的用户代码，Disruptor没有定义特定接口或类型。 三、如何使用Disruptor 1. 定义事件 事件(Event)就是通过 Disruptor 进行交换的数据类型。 public class LongEvent { private long value; public void set(long value) { this.value = value; } } 2. 定义事件工厂 事件工厂(Event Factory)定义了如何实例化前面第1步中定义的事件(Event)，需要实现接口 com.lmax.disruptor.EventFactory。 Disruptor 通过 EventFactory 在 RingBuffer 中预创建 Event 的实例。 一个 Event 实例实际上被用作一个“数据槽”，发布者发布前，先从 RingBuffer 获得一个 Event 的实例，然后往 Event 实例中填充数据，之后再发布到 RingBuffer 中，之后由 Consumer 获得该 Event 实例并从中读取数据。 import com.lmax.disruptor.EventFactory; public class LongEventFactory implements EventFactory { public LongEvent newInstance() { return new LongEvent(); } } 3. 定义事件处理的具体实现 通过实现接口 com.lmax.disruptor.EventHandler 定义事件处理的具体实现。 import com.lmax.disruptor.EventHandler; public class LongEventHandler implements EventHandler { public void onEvent(LongEvent event, long sequence, boolean endOfBatch) { System.out.println(\"Event: \" + event); } } 4. 定义用于事件处理的线程池 Disruptor 通过 java.util.concurrent.ExecutorService 提供的线程来触发 Consumer 的事件处理。例如： ExecutorService executor = Executors.newCachedThreadPool(); 5. 指定等待策略 Disruptor 定义了 com.lmax.disruptor.WaitStrategy 接口用于抽象 Consumer 如何等待新事件，这是策略模式的应用。 Disruptor 提供了多个 WaitStrategy 的实现，每种策略都具有不同性能和优缺点，根据实际运行环境的 CPU 的硬件特点选择恰当的策略，并配合特定的 JVM 的配置参数，能够实现不同的性能提升。 例如，BlockingWaitStrategy、SleepingWaitStrategy、YieldingWaitStrategy 等，其中，BlockingWaitStrategy 是最低效的策略，但其对CPU的消耗最小并且在各种不同部署环境中能提供更加一致的性能表现； SleepingWaitStrategy 的性能表现跟 BlockingWaitStrategy 差不多，对 CPU 的消耗也类似，但其对生产者线程的影响最小，适合用于异步日志类似的场景； YieldingWaitStrategy 的性能是最好的，适合用于低延迟的系统。在要求极高性能且事件处理线数小于 CPU 逻辑核心数的场景中，推荐使用此策略；例如，CPU开启超线程的特性。 WaitStrategy BLOCKING_WAIT = new BlockingWaitStrategy(); WaitStrategy SLEEPING_WAIT = new SleepingWaitStrategy(); WaitStrategy YIELDING_WAIT = new YieldingWaitStrategy(); 6. 启动Disruptor EventFactory eventFactory = new LongEventFactory(); ExecutorService executor = Executors.newSingleThreadExecutor(); int ringBufferSize = 1024 * 1024; // RingBuffer 大小，必须是 2 的 N 次方； Disruptor disruptor = new Disruptor(eventFactory, ringBufferSize, executor, ProducerType.SINGLE, new YieldingWaitStrategy()); EventHandler eventHandler = new LongEventHandler(); disruptor.handleEventsWith(eventHandler); disruptor.start(); 7. 发布事件 Disruptor 的事件发布过程是一个两阶段提交的过程： 第一步：先从 RingBuffer 获取下一个可以写入的事件的序号； 第二步：获取对应的事件对象，将数据写入事件对象； 第三部：将事件提交到 RingBuffer; 事件只有在提交之后才会通知 EventProcessor 进行处理； // 发布事件； RingBuffer ringBuffer = disruptor.getRingBuffer(); long sequence = ringBuffer.next();//请求下一个事件序号； try { LongEvent event = ringBuffer.get(sequence);//获取该序号对应的事件对象； long data = getEventData();//获取要通过事件传递的业务数据； event.set(data); } finally{ ringBuffer.publish(sequence);//发布事件； } 注意，最后的 ringBuffer.publish 方法必须包含在 finally 中以确保必须得到调用；如果某个请求的 sequence 未被提交，将会堵塞后续的发布操作或者其它的 producer。 Disruptor 还提供另外一种形式的调用来简化以上操作，并确保 publish 总是得到调用。 static class Translator implements EventTranslatorOneArg{ @Override public void translateTo(LongEvent event, long sequence, Long data) { event.set(data); } } public static Translator TRANSLATOR = new Translator(); public static void publishEvent2(Disruptor disruptor) { // 发布事件； RingBuffer ringBuffer = disruptor.getRingBuffer(); long data = getEventData();//获取要通过事件传递的业务数据； ringBuffer.publishEvent(TRANSLATOR, data); } 此外，Disruptor 要求 RingBuffer.publish 必须得到调用的潜台词就是，如果发生异常也一样要调用 publish ，那么，很显然这个时候需要调用者在事件处理的实现上来判断事件携带的数据是否是正确的或者完整的，这是实现者应该要注意的事情。 8. 关闭 Disruptor disruptor.shutdown();//关闭 disruptor，方法会堵塞，直至所有的事件都得到处理； executor.shutdown();//关闭 disruptor 使用的线程池；如果需要的话，必须手动关闭， disruptor 在 shutdown 时不会自动关闭； "},"java/multi_thread/threa_basic.html":{"url":"java/multi_thread/threa_basic.html","title":"1、线程的基本概念","keywords":"","body":"1 进程与线程的基本概念 1.1 时间片。 时间片就是cpu分配给各个程序的时间，每一个线程将会被分配一个时间段，称作它为时间片，即进程允许的时间。使得程序在表面上看是同时进行的。当一个时间片结束时并且进程还运行的时候，将会把cpu分配给另外一个进程；当时间片结束前发生阻塞或者结束，cpu也会进行切换。这样避免cpu资源的浪费。 也可以从宏观上以及微观上来解释。在宏观上：我们可以同时打开多个应用程序，每个程序并行不悖，同时运行。但在微观上：由于只有一个CPU，一次只能处理程序要求的一部分，如何处理公平，一种方法就是引入时间片，每个程序轮流执行。【摘自百度百科】 在我们并发编程中，有两个基本的执行单元，分别是：进程和线程。在编程中用得比较多的是线程。 1.2 进程 进程是系统进行资源分配和调度的基本单位，进程也是正在运行的程序的实例，进程往往被看作是程序或应用的代名词。 进程的特征： 动态性：进程的实质是程序在多道程序系统中的一次执行过程，进程是动态产生，动态消亡的。 并发性：任何进程都可以同其他进程一起并发执行 独立性：进程是一个能独立运行的基本单位，同时也是系统分配资源和调度的独立单位; 异步性：由于进程间的相互制约，使进程具有执行的间断性，即进程按各自独立的、不可预知的速度向前推进。 结构特征：进程由程序、数据和进程控制块三部分组成。 多个不同的进程可以包含相同的程序：一个程序在不同的数据集里就构成不同的进程，能得到不同的结果;但是执行过程中，程序不能发生改变。 1.3 线程 线程是程序执行流的最小单元，线程有时也会被称之为轻量级的进程。通常创建一个线程比创建一个进程消耗的资源少。 线程存在于进程中，每一个进程至少存在于一个线程。 1.4 同步、异步和阻塞、非阻塞 其中同步以及异步是针对应用程序和内核的交互而言的。 阻塞以及非阻塞是针对进程在访问数据的时候。 同步阻塞IO： 用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才可以运行。（java传统的IO模型就属于这种方式） 同步非阻塞IO： 用户发起一个IO操作以后可以返回做其他的事情，但是用户需要时不时地询问IO操作是否完成，这就要求用户不断地去询问，从而引入了不必要的CPU资源浪费。（其中JAVA的NIO就属于同步非阻塞IO）。 1.5 线程安全？ 共享的全局变量的访问必须保证不受多线程的影响。如果由于多线程的访问（比如：修改、遍历、查看）而使这些成员变量结构被破坏或者针对这些变量的原子性被破坏，则就不是线程安全的。 "},"java/multi_thread/thread_lock.html":{"url":"java/multi_thread/thread_lock.html","title":"2、线程锁","keywords":"","body":"重入锁、读写锁、锁的高级深化 1. CountDownLatch 一个线程或多个线程一直等待，直到其他线程的操作完成。CountDownLatch用一个给定的计数器来初始化，该计数器操作是原子性的。调用该类的await方法的线程会一直处于阻塞状态，直到其他线程调用countDown方法使当前计数器的值变为0，每次调用countDown计数器减1。只有当计数器为0的时候，所有调用await()方法而处于等待状态的线程会继续执行下去。这种现象只会出现一次，因为计数器不能被重置。 2. CyclicBarrier CycliBarrier也是一个同步辅助类，它允许一组线程相互等待，直到达到某个公共屏障点。通过它可以完成线程之间相互等待，只有在每个线程都准备就绪后，才能各自继续往下执行，CycllicBarrier在释放等待线程后才可以重用，所以也称之为循环barrier。 3. Semaphonre 可以控制同时访问线程个数，可以通过acquire()获取一个许可，如果没有就等待，而release()释放一个许可。 示列代码： public class Test { public static void main(String[] args) { int N = 8; //工人数 Semaphore semaphore = new Semaphore(5); //机器数目 for(int i=0;i ​ 4. ReentrantLock（重入锁） java.util.concurrent.lock中的Lock是锁的一个抽象，ReentrantLock类实现了Lock，它拥有与synchronized相同的并发性和内存语义，代码如下所示： class Outputter1 { private Lock lock = new ReentrantLock();// 锁对象 public void output(String name) { lock.lock(); // 得到锁 try { for(int i = 0; i 5. ReadWriteLock（读写锁） 允许多个线程可以同时读取，但是只能有一个线程修改共享数据（适合读多写少的情况） 代码如下所示： class Data { private int data;// 共享数据 private ReadWriteLock rwl = new ReentrantReadWriteLock(); public void set(int data) { rwl.writeLock().lock();// 取到写锁 try { System.out.println(Thread.currentThread().getName() + \"准备写入数据\"); try { Thread.sleep(20); } catch (InterruptedException e) { e.printStackTrace(); } this.data = data; System.out.println(Thread.currentThread().getName() + \"写入\" + this.data); } finally { rwl.writeLock().unlock();// 释放写锁 } } public void get() { rwl.readLock().lock();// 取到读锁 try { System.out.println(Thread.currentThread().getName() + \"准备读取数据\"); try { Thread.sleep(20); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \"读取\" + this.data); } finally { rwl.readLock().unlock();// 释放读锁 } } } 6. Condition Condition用于线程之间的通信，用于替代Object的wait()、notify()实现线程间的协作，相比使用Object的wait()、notify(),使用Condition的await()、signal()这种方式实现线程间协作更加安全和高效。推荐使用Condition public class ConTest { final Lock lock = new ReentrantLock(); final Condition condition = lock.newCondition(); public static void main(String[] args) { // TODO Auto-generated method stub ConTest test = new ConTest(); Producer producer = test.new Producer(); Consumer consumer = test.new Consumer(); consumer.start(); producer.start(); } class Consumer extends Thread{ @Override public void run() { consume(); } private void consume() { try { lock.lock(); System.out.println(\"我在等一个新信 号\"+this.currentThread().getName()); condition.await(); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } finally{ System.out.println(\"拿到一个信号\"+this.currentThread().getName()); lock.unlock(); } } } class Producer extends Thread{ @Override public void run() { produce(); } private void produce() { try { lock.lock(); System.out.println(\"我拿到锁\"+this.currentThread().getName()); condition.signalAll(); System.out.println(\"我发出了一个信号：\"+this.currentThread().getName()); } finally{ lock.unlock(); } } } } 7. 公平锁以及非公平锁？ 公平锁是指哪个线程会先运行，那就可以先获取到锁。非公平锁是不管线程是否先运行，都随即获得锁。 在Lock中默认使用非公平锁（不加顺序），效率比公平锁更高。公平锁会维护锁的顺序，因此效率没有那么高。 8. synchronized 弊端 在执行synchronized声明的方法有时候也有弊端，比如A线程的同步方法执行一个很长时间的任务，那么B线程就必须等待比较长的时间才能执行，这种情况下可以使用synchronized代码去优化代码执行的时间。 不要使用String的常量去加锁，会出现死循环。 "},"java/multi_thread/thread_notify.html":{"url":"java/multi_thread/thread_notify.html","title":"3、线程通信","keywords":"","body":"Volatile关键字、线程之间的通信（wait、notify） 1. Volatile关键字 作用 实现变量在多个线程之间的可见性，但是并不具备同步性（也就是原子性），可以算是轻量级的synchronized强很多，不会造成阻塞 如果该变量用了volatile修饰，则会强制程序在主内存中去取值，而不是在线程工作内存中获取。 Tips 一般volatile用于只针对多个线程可变的变量操作，并不能替代synchronized的同步功能。 2.线程之间的通信 概念 线程是操作系统的个体，但这些个体如果不经过特殊的处理就不能成为一个整体，线程间的通信就成为整体的比用方式之一。当线程存在通信指挥，系统间的交互性会更加的强大，在提高CPU利用率的同时还会使开发者对线程任务处理的过程中进行有效的把控与监督。 用法与作用 使用wait和notify必须配合synchronized关键字使用 如果对象调用了wait方法就会使持有该对象的线程把该对象的控制权交出去，然后处于等待状态。 如果对象调用了notify方法就会通知某个正在等待这个对象的控制权的线程可以继续运行。 如果对象调用了notifyAll方法就会通知所有等待这个对象控制权的线程继续运行。 "},"java/multi_thread/thread_pattern.html":{"url":"java/multi_thread/thread_pattern.html","title":"4、多线程常用模式","keywords":"","body":"1. Future模式 1.1 Future模式核心思想 Future模式的核心在于去除主函数的等待时间，并使得原本需要等待的时间段可以用于处理其他的业务逻辑。 Future模式类似于商品订单。在网上购物，提交订单之后需要在家等待，并且可以做其他的事情。在程序设计中，当请求提交的时候，期望得到答案时，如果这个答复很慢，传统的是一直等待这个答复之后在去做别的事情，如果利用Future设计模式就无需等待答复的到来，在等待答复的过程中可以做其他的事情。 如下面的时序图所示： 1.2 代码： Client： public class Client { public Data request(final String string) { final FutureData futureData = new FutureData(); new Thread(new Runnable() { @Override public void run() { //RealData的构建很慢，所以放在单独的线程中运行 RealData realData = new RealData(string); futureData.setRealData(realData); } }).start(); return futureData; //先直接返回FutureData } } Data： public interface Data { String getResult() throws InterruptedException; } FutureData: public class FutureData implements Data{ private RealData realData; private boolean isReady = false; public RealData getRealData() { return realData; } public synchronized void setRealData(RealData realData) { if (isReady){ return; } this.realData = realData; isReady = true; notifyAll(); } @Override public synchronized String getResult() throws InterruptedException { if (!isReady){ wait(); } return realData.getResult(); } } RealData: public class RealData implements Data{ private String data; public RealData(String data) { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } this.data = data; } @Override public String getResult() throws InterruptedException { return this.data; } } Main: public class Main { public static void main(String[] args) throws InterruptedException { Client client = new Client(); //这里会立即返回，因为获取的是FutureData，而非RealData Data data = client.request(\"name\"); //这里可以用一个sleep代替对其他业务逻辑的处理 //在处理这些业务逻辑过程中，RealData也正在创建，从而充分了利用等待时间 // Thread.sleep(2000); //使用真实数据 System.out.println(\"数据=\"+data.getResult()); } } 2. Master-Worker模式 2.1 概念 Master-Worker模式是常用的并行计算模式。它的核心思想就是系统由两类进行协同工作：Master进程和Worker进程。Master负责接收和分配任务，Worker负责处理子任务。当各个Worker子进程处理完成之后，会将结果返回给Master，由Master做归纳和总结。 优点： 将一个大的任务分解成为若干个小任务，并行执行，从而提高系统吞吐量。 2.2 代码 Task public class Task { private int id; private String name; private long price; public Task() { } public Task(int id, String name, long price) { this.id = id; this.name = name; this.price = price; } public int getId() { return id; } public void setId(int id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } public long getPrice() { return price; } public void setPrice(long price) { this.price = price; } } Work public class Work implements Runnable{ private ConcurrentLinkedDeque workQueue; private ConcurrentHashMap resultMap; @Override public void run() { while (true){ Task input = this.workQueue.poll(); if (input == null){ break; } //处理任务 Object result = handle(input); this.resultMap.put(Integer.toString(input.getId()), result); } } private Object handle(Task task) { try { Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } return task.getPrice(); } public void setWorkQueue(ConcurrentLinkedDeque workQueue) { this.workQueue = workQueue; } public void setResultMap(ConcurrentHashMap resultMap){ this.resultMap = resultMap; } } Master } /** * 用于分配任务 * 收集结果集 */ public class Master { //1. 装配任务的集合 private ConcurrentLinkedDeque workQueue = new ConcurrentLinkedDeque(); //2. 装配work private HashMap works = new HashMap<>(); //3. 装配结果集 private ConcurrentHashMap resultsMap = new ConcurrentHashMap<>(); //4. 构造方法 public Master(Work work, int countWork) { work.setWorkQueue(this.workQueue); work.setResultMap(this.resultsMap); for (int i=0; i me :this.works.entrySet()){ me.getValue().start(); } } public Object getResut(){ long result = 0; for (Map.Entry me:resultsMap.entrySet()){ result += (Long)me.getValue(); } return result; } public boolean isComplete() { for (Map.Entry me:works.entrySet()){ if (me.getValue().getState() != Thread.State.TERMINATED){ return false; } } return true; } } Client public class Client { public static void main(String[] args){ Work work = new Work(); Master master = new Master(work, 10); Random random = new Random(); for (int i=0;i "},"java/multi_thread/Executor.html":{"url":"java/multi_thread/Executor.html","title":"5、Executor框架以及线程池","keywords":"","body":"1 Executor框架 1 Executors创建线程池的方法 newFixedThreadPool方法，该方法返回一个固定数量的线程池，该方法的线程数始终不会发生改变，当有一个任务提交的时候，若线程池中空闲，则立即执行，若没有，则会被暂缓在一个任务队列中等待有空闲的的线程去执行。采用的队列是:LinkedBlockingQueue newSingleThreadExecutor()方法，创建一个线程的线程池，若空闲则执行，若没有，空闲线程池则暂缓在任务队列中,采用的队列是：LinkedBlockingQueue newCachedThreadPool()方法，返回创建一个可根据实际情况调整线程个数的线程池，不限制最大线程数量。若无空闲线程，则创建，并且每一个线程会在60s后自动回收。采用的队列是：SychronousQueue newScheduledThreadPool()方法，该方法返回一个SchededExecutorService对象，但该线程可以指定线程的数量。采用的队列是：DelayedWorkQueue 2. ThreadPoolExecutor? 利用Executors创建的线程池都会实例化ThreadPoolExecuor对象。 "},"java/multi_thread/thread_queue.html":{"url":"java/multi_thread/thread_queue.html","title":"6、多线程队列","keywords":"","body":"1. 队列的分类？ 队列可以分为阻塞队列以及非阻塞队列 阻塞队列(BlockingQueue)： ArrayBlockingQueue LinkedBlockingQueue PriorityBlockingQueue DelayQueue SynchronousQueue 非阻塞队列 ConcurrentLinkedQueue 2. 阻塞队列 2.1 ArrayBlockingQueue 在构造的时候需要指定容器的大小，是有界的阻塞队列。 2.2 LinkedBlockingQueue 默认的情况下该队列是没有上限的。但是也可以指定最大的容量。 2.3 PriorityBlockingQueue 该队列是没有上限的，在元素移除的时候是按照优先级顺序进行移除。 2.4 DelayQueue 是一个存放Delayed元素的无界阻塞队列，只有在延期满时才取出元素。 2.5 SynchronousQueue 一种无缓冲的等待队列，类似于无中介的直接交易。 "},"java/collection.html":{"url":"java/collection.html","title":"集合","keywords":"","body":"1.如何将map非线程安全转变为线程安全的（不推荐使用）？ 通过同步类容器来将非线程安全转变为线程安全的，Collections.synchronizedMap(new HashMap()) //其中可以将非线程安全的map、set、list转变为线程安全的集合 Map map = Collections.synchronizedMap(new HashMap()) 2. HashTable、Vector等同步类容器实现线程安全有什么缺点？ 这种旧版的JDK实现线程安全的通常是Collections.synchronized*等工厂方法创建实现的，其底层的机制无非就是用传统的synchronized关键字对每个公用的方法进行同步，使得每一次只能有一个线程访问容器的状态（性能较低）。 3.ConCurrentMap如何实现高并发操作并且保证线程安全的？ 内部使用段来表示不同的部分，每个段其实就是一个小的HashTable，他们有自己的锁。只要多个修改不发生在同一个段中，他们就可以并发进行。把一个整体分成16个段。也就是最高支持16个线程的并发修改操作。这也是在多线程场景中减小锁的粒度从而降低锁竞争的一种方案，并且代码中大多数共享变量使用volatile关键字声明，目的是第一时间获取修改的内容，性能非常好。 4. Copy-On-Write容器 Copy-On-Write简称COW，是一种用于程序设计中的优化策略。 适用场景：读多 写少 JDK中的COW容器有两种：CopyOnWriteArrayList和CopyOnWriteArraySet。 什么是CopyOnWrite容器 CopyOnWrite容器即写时复制的容器。也就是说当我们往容器中添加元素的时候，不直接往当前容器中添加，而是将当前容器进行Copy，复制出一个新的容器。这样做的好处就是可以对CopyOnWrite容器惊醒并发的读，而不需要加锁，因为当前容器不会添加任何东西。CopyOnWrite也是一种读写分离的思想，读和写不同的容器。 "},"javaweb/readme.html":{"url":"javaweb/readme.html","title":"第三部分 Java Web","keywords":"","body":""},"javaweb/spring/readme.html":{"url":"javaweb/spring/readme.html","title":"3.1、Spring","keywords":"","body":""},"python/readme.html":{"url":"python/readme.html","title":"第四部分 Python知识点","keywords":"","body":""},"python/basic/readme.html":{"url":"python/basic/readme.html","title":"4.1、Python","keywords":"","body":""},"python/basic/python_explain.html":{"url":"python/basic/python_explain.html","title":"4.1.1、python解释器比较","keywords":"","body":"python集中解释器的比较 1. CPython Cpython是用C语言开发的，所以叫做CPython，CPython也是使用最广泛的python解释器。 2. IPython IPython是基于CPython之上的一个交互式解析器，也就是说，IPython只是在交互 方式上有所加强，但是执行Python代码的功能和CPython是完全一样的。 3. PyPy PyPy是另一个Python解释器，它的目标是执行速度。PyPy采用JIT技术，对Python代码进行动态编译，并且可以显著的提高Python代码的执行速度。 绝大部分Python代码都可以在PyPy下运行，但是PyPy和CPython有一些不同的，这就导致相同的Python代码在两种解释器下执行可能会有不同的结果。 4. Jython Jython是运行在Java平台的Python解释器，可以直接把python代码编译成Java字节码执行。 5. IronPython IronPython和Jython类似，只不过IronPython是运行在.net平台上的Python解释器，可以直接把python代码编译成.net字节码。 "},"python/basic/python_basic.html":{"url":"python/basic/python_basic.html","title":"4.1.2、python基础知识","keywords":"","body":"1. 基础数据类型 整数 python可以处理任意大小的整数，当然包括负整数，写法为：1，100，-100 浮点数 浮点数也就是小数，表示方式为：0.98，-90.09 字符串 字符串是以单引号'或双引号\"括起来的任意文本 布尔值 布尔值和布尔数值的表示一致，一个布尔值只有True、False两种值。布尔值可以使用and（与运算）、or（或运算）、not（非运算）运算。 空值 空值是python里的一个特殊的值，用None表示。 变量 变量可以是任意数据类型，变量名必须是大小英文、数字、和_的组合，不能用数字开头。如：a = 100; 静态类型与动态类型： 静态类型需要在对应的变量前面指定对应的数据类型。 int a = 123; 2. list与tuple list list是一种数据类型的列表，是一种有序的集合，可以随时的添加以删除其中的元素，如： classmates = ['dai','li','ming']　　#list集合 len(classmates)　　#list的长度 classmates.append('zhang')　　#在list最后添加元素 classmates.insert(1,'ok')　　#在位置1添加“ok” classmates.pop()　　#删除list后面的元素 classmates.pop(i)　　#删除第i个元素 classmates[1] = 'Sarah'　　#修改位置1的的元素的值 L = ['Apple', 123, True]　　#list集合也可以有不同的数据类型 tuple tuple是另外一种有序列表，也叫做元组。tuple和list非常相似，tuple一旦初始化了之后就不能修改，表示形式为： classmates = ('dai','li','ming') t = ('a', 'b', ['A', 'B']) t[2][0] = 'X' t[2][1] = 'Y'#t为('a', 'b', ['X', 'Y']) dict（字典）与set python内置了字典，其他语言称之为map，使用key-value存储：如： d = {'Michael': 95, 'Bob': 75, 'Tracy': 85} set和dict类似，也是一组key的集合，但是不能存储value。由于key不能重复，所以set中不能重复。如： s = set([1, 2, 3]) 3. 函数 函数的定义需要使用def语句，依次写出函数名、括号、括号中的参数以及冒号：,然后代码缩进块中编写函数体，函数的返回值使用return语句返回如下： def my_abs(x): 　　if x >= 0: 　　　　return x 　　else: 　　　　return -x 空函数：定义一个空函数需要使用pass语句。 函数还可以返回多个值，如下所示： def move(x, y, step, angle=0): 　　nx = x + step * math.cos(angle) 　　ny = y - step * math.sin(angle) 　　return nx, ny x, y = move(100, 100, 60, math.pi / 6) "},"python/basic/python_compare.html":{"url":"python/basic/python_compare.html","title":"4.1.3、python常见知识区别","keywords":"","body":"python常见的知识点(2.7) 1. 列表（list）、元组（tupe）、字典（dict）、set的区别？ 列表（list） list是python种内置的一种数据类型，list是一种有序的集合，可以随时添加和删除其中的元素。其中list越大，查找速度越慢。查找和插入的时间随着元素的增加而增加；需要占用空间小，浪费内存小。表示方式为： classmates = ['Michael', 'Bob', 'Tracy'] 元组（tupe） 另外一种有序列表是元组（tupe），和list非常相似，但是tupe一旦被初始化了之后就不能被修改，表示方式如下： classmates = ('Michael', 'Bob', 'Tracy') 字典 python内置了字典，在其他的语言中称之为map，使用的是键-值（key-value）方式存储，key不能重复。查找和插入速度快，但是需要占用大量的内存，内存浪费多。表示方式如下所示： d = {'Michael': 95, 'Bob': 75, 'Tracy': 85} set set和dic类似，也是一组key的集合，但是不能存储value。其中对应存储的key不能重复，其中set和dict的原理相同。创建对应的set的代码如下所示： s = set([1, 2, 3])2. locals()的作用？ locals()返回一个包含当前作用域里面的所有的变量和他们的值的字典。 3. Django中间件，如何配置，作用如何？ 什么是中间件？ 中间件是介于request与response处理之间的一道处理过程，相对比较轻量级，在全局上改变django的输入以及输出。需要谨慎使用，会影响性能。其中每一个中间件会负责一个功能，例如：AuthenticationMiddleware与session处理相关。 中间件如何配置？ 需要在setting.py中配置（或者在对应的项目的配置文件配置），配置的是 - MIDDLEWARE_CLASSES: MIDDLEWARE_CLASSES = [ 'django.middleware.security.SecurityMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', ] 中间件的执行顺序？ 我们从浏览器发出一个请求（Request）之后，得到一个响应的内容(HttpResponse),这个过程如下所示： 在每次的请求的时候都会按照配置文件中的顺序执行中间件的proccess_resuest函数，该函数会返回None或者HttpResponse（如果该函数返回None则继续执行，如果返回HttpResonse对象则不会继续执行相应的中间件或者view），其中的proccess_response会在最后执行，按照定义的中间件的相反顺序执行。 如何编写中间件？ 中间件不用继承任何类（可以继承object），代码如下所示： class CommonMiddleware(object): 　　　def process_request(self, request): 　　　　　return None 　　　def process_response(self, request, response): 　　　　　return response 4. Django如何实现多表的查询？ 查询小明的所有完整信息 AuthorDetail.objects.values('sex',....) * 查询活着这本书的作者以及出版社名字 * Book.objects.filter(title='活着').value('author__name','publisher__name') * 查询小明写了什么书 * BOOK.objects.filter(author__name='小明').value('title') *tips: __：两个下划线可以生成表连接查询，查询关联的字段信息 _set：提供了对象访问相关联数据的方法。但是这种方法只能是相关类定义了关系的类（主键类访问外键类） filter表示 = execlude表示 != querySet.distinct()去重 __exact　精确等于 like 'aa' __iexact　 精确等于　忽略大小写　ilike 'aa' __contaions 包含 like '%aa%' __icontaions 包含 忽略大小写 ilke '%aa%' * __gt 大于 * __gate 大于等于 * __it 小于 * __ite 小于等于 * __in 存在与一个list范围内 * __startswith 以..开头 * __istartswith 以..开头 忽略大小写 * __endswith 以..结尾 * __iendswith 以..结尾 忽略大小写 * __range 在..范围内 * __year 日期字段的年份 * __month 日期字段的月份 * __day 日期字段的日 * __isnull 日期字段的年份 6.Django中常用的注解有哪些？作用是什么？ * 7.Django中内部Meta Django模型是一个内部类、它用于定义一些Django模型类的行为特征。以下为可选的选项 abstract Django模型是定义当前模型不是一个抽象类。所谓抽象类是不会有对应的数据库表的。一般用于归纳一些公共属性字段，然后继承它的子类可以继承这些字段。 如果abstract=True，说明这个模型就是一个抽象类。 app_label 这个选项只有在一种情况下使用，就是你的模型不在默认的应用程序的models.py文件中，这时需要你指定你的模型是哪个应用程序的。 db_table db_table是指自定义数据库的表名。 db_tablespace 定义这个model所使用的数据库表空间。 get_latest_by 在model中指定一个DateField或者DateTimeField。这个设置让你在使用model的Manager上的latest方法时，默认使用指定字段来排序。 managed 默认值为True，这意味着Django可以使用命令来创建或移除对应的数据库。 order_with_respect_to 这个选项一般多用于多对多的关系中，它指向一个关联对象，就是说关联对象找到这个对象后是它经过排序的。指定这个属性之后会得到一个get_XXX_order（）和set__XXX_order()的方法 ordering 这个字段是告诉Django模型对象返回的结果是按照哪个字段排序： ordering=['ordering'] #按照订单的升序排列 ordering=['-ordering'] #按照订单的降序排列 - 表示降序 ordering=['ordering'] #随即排序 ordering=['ordering','-username'] #按照ordering升序，按照username进行降序排序 permissions permissions主要是为了在Django Admin管理模块下使用的，如果设置了这个属性，可以让指定的方法权限描述更加清晰可读。Django自动为每个设置了admin对象创建添加，删除和修改的权限。 proxy 为了实现代理模式，如果proxy=True，表示model是其父的代理model。 unique_together 需要使两个字段保持唯一的时候使用 verbose_name verbose_name就是给你的模型起一个更加可读的名字，一般定义为中文 verbose_name_plural 这个选项值得是模型的复数形式 8.Django是如何实现用户拦截的？ 在url.py中添加如下代码： urlpatterns += required( partial(staff_member_required, login_url='backend:login'), 　　 urlpatterns ) 9.Django事务 管理数据库事务 Django默认的行为是运行在自动提交模式下的，任何一个查询都立即被提交到数据库中，除非激活一个事务 把事务绑定在HTTP请求上 在web上的一种简单处理事务的方式是将每个请求用事务包装起来。在每个你想保存这种行为数据的配置文件中，设置ATOMIC_REQUESTS值为True 工作的过程：在调用一个view里面的方法之前，django开始一个事务，如果发出的相应没有什么问题，Django就会提交这个事务。如果在view里产生异常，Django就会回滚事务。 在实际的操作中，可以通过如下atomic()装饰器把这一功能简单地加载到视图函数上。 表示事务仅仅是当前视图有效，诸如模版响应之类的中间件操作是运行在事务之外的 @transaction.non_atomic_requests def my_view(request): 　 do_stuff() 更加明确的控制事务 from django.db import IntegrityError, transaction @transaction.atomic def viewfunc(request): create_parent() try: with transaction.atomic(): generate_relationships() except IntegrityError: handle_exception() add_children() 10.Django如何处理一个请求 当一个用户请求Django站点的一个页面，下面是Django系统决定执行哪个python代码： Django决定要使用的根URLconf模块。通常，这个值就是ROOT_URL_CONF的设置，但是如果进来的HttpResquest对象具有一个urlconf属性（通过中间件request proccessing设置），则使用这个值替换ROOT_URL_CONF设置。 Django加载该Python模块并寻找可用的urlpatterns。它是django.conf.urls.url() 实例的一个Python 列表。 Django 依次匹配每个URL 模式，在与请求的URL 匹配的第一个模式停下来。 一旦其中的一个正则表达式匹配上，Django 将导入并调用给出的视图，它是一个简单的Python 函数（或者一个基于类的视图）。 * 如果没有匹配到正则表达式，或者如果过程中抛出一个异常，Django 将调用一个适当的错误处理视图。 11.自定义错误视图 handler404 = 'mysite.views.my_custom_page_not_found_view' handler500 = 'mysite.views.my_custom_error_view' handler403 = 'mysite.views.my_custom_permission_denied_view' handler400 = 'mysite.views.my_custom_bad_request_view' 12.如何限制HTTP的请求方法 @require_http_methods([\"GET\", \"POST\"]) def my_view(request): do_task() require_GET() 只允许视图接受GET方法的装饰器。 require_POST() 只允许视图接受POST方法的装饰器。 equire_safe() 只允许视图接受 GET 和 HEAD 方法的装饰器。 这些方法通常被认为是安全的，因为方法不该有请求资源以外的目的 13.在session中添加用户信息以及退出一个用户 需要先调用authenticate(),当成功的认证该用户的时候，之后才会调用login() 通过logout(request)退出用户 14.如何实现只允许登录的用户访问？ 可以通过代码：request.user.is_authenticated()是否登陆 也可以通过login_required 装饰器 如果用户没有登陆，则会从定向到settings.LOGIN_URL,并将当前的访问路径传递到查询字符串中。 如果用户已经登陆了，则正常执行视图，视图的代码可以安全地假设用户已经登陆了。 15.permission_required 装饰器的作用？ 用于检查一个用户是否有指定的权限 16.怎样重写用户模型？ Django中内置的User模型不可能适合所有的项目，可以通过AUTH_USER_MODEL设置覆盖默认的User模型，其值引用一个定义的模型。 AUTH_USER_MODEL = 'myapp.MyUser' 自定义的模型需要满足的要求如下所示： 模型必须要有一个唯一的字段可被用于识别目的。 创建一个规范的自定义模型的最简单的方法是继承AbstractBaseUser。AbstractBaseUser提供User模型的核心实现，包括散列密码和令牌化密码重置。必须提供一些关键的实施细节： USERNAME_FIELD 描述User模型上用作唯一标识符的字段名称的字符串，字段必须是唯一的。 REQUIRES_FIELDS 列出必须的字段 is_active 指示用户是否被视为“活动”的布尔属性，默认为True。如何选择实施它取决于选择身份验证后端的信息。 get_full_name() 用户更长且正式的标识，常用的解释会是用户的完整名称，可以是任何字符串 get_short_name()一个短的并且正式的用户标识符。 自定义了User模型之后，如果你的User模型定义了username、email、is_staff、is_active、is_superuser、last_login、date_joined跟默认的字段是一样的话，那么你就使用Django的UserManager就行了；总之，如果定义了有不同的字段的时候，你就需要自定义一个管理器，它继承BaseUserManager并提供两个额外的方法。 create_user(username,password=None,other_fields) create_superuser(username,password,other_fields) 其中create_user()和create_superuser()不同，其中create_superuser()必须要求调用方提供密码 17.用户定义以及权限 为了将Django的权限框架包含在自己的User类中，Django提供了PermissionsMixin。提供支持Django权限模型所需要的所有方法和数据库的字段。 18.用户认证自定义（一般用于自己重写user之后） 在stting.py中设置： AUTHENTICATION_BACKENDS= ( 　　 'users.views.CustomBackend', 　　 ) # 其中定义的为用户自定义的认证对象，代码如下（需要继承ModelBackend对象，重写authenticate()方法）： class CustomBackend(ModelBackend): def authenticate(self, username=None, password=None, **kwargs): try: user = UserProfile.objects.get(Q(username = username)|Q(email=username)) if user.check_password(password): return user except Exception as e: return None 19. *args和**args的区别? 用当你不确定你的函数里将要传递多少参数的时候，可以使用*args，可以传递任意参数 **相似的，**kwargs允许你使用没有实现预定好的参数名 20.装饰器的作用？ 为已经存在的对象添加额外的功能。 21.python中的重载 重载主要解决两个问题： 可变参数类型 可变参数的个数 22.new和init的区别？ 这个_new_是一个静态方法区，而__init\\是一个实例方法。 _new_方法会返回一个创建的实例，而__init\\什么都不会返回 只有在_new_返回一个class的实例时后面的__init\\才能被调用 当创建一个新的实例时调用_new_，初始化一个实例用__init\\ 22. Python垃圾回收机制 Python GC主要使用引用计数来跟踪和回收垃圾。在引用计数的基础上，通过“标记-清除”解决容器对象可能产生的循环引用问题，通过“分代回收”以空间换时间的方法提高垃圾回收效率。 引用计数法 PyObject是每个对象必有的内容，其中ob_refcnt就是为引用计数。当一个对象有新的引用的时候，它的ob_refcnt就会增加，当引用它的对象被删除的时候，它的ob_refcnt就会减少。当obj_refcnt为0的时候，该对象的生命就结束了。 优点： 简单 实时性 缺点 维护引用计数消耗资源 循环引用 标记-清除机制 基本思路就是先按需分配，等到没有空闲的时候从寄存器和程序栈上引用出发，遍历以对象为节点、以引用为边构成图，把所有可以访问的对象上打上标记，然后清扫一遍内存空间，把没有标记的对象释放。 分代技术 分代回收的整体思想是：将系统中的所有内存块根据其存活的时间划分为不同的集合，每个集合就成为一个“代”。垃圾收集频率随着“代”的存活时间的增大而减小，存活时间通常利用经过几次垃圾回收来度量。 Python默认定义了三代对象集合，索引数越大，对象存活时间越长。 23. python中的is与==？ python中的is是对比地址，==是对比值 24.read、readline和readlines read读取整个文件 readline读取下一行，使用生成器方法 readlines读取整个文件到一个迭代器以供我们遍历 25. 如何在一个文件夹中创建多个app？ 先将创建好的app复制到指定的文件夹中，然后在settings.py中添加代码： sys.path.insert(0, os.path.join(BASE_DIR, 'app')) "},"python/basic/python_env.html":{"url":"python/basic/python_env.html","title":"4.1.4、python创建虚拟环境","keywords":"","body":"python 虚拟环境 sudo pip install virtualenv sudo pip install virtualenvwrapper mkdir $HOME/.virtualenvs vi ~/.bashrc 添加 export WORKON_HOME=$HOME/.virtualenvs export PROJECT_HOME=/home/pengfei/Desktop/data/mysite/imgxe/ export VIRTUALENVWRAPPER_SCRIPT=/usr/local/bin/virtualenvwrapper.sh source /usr/bin/virtualenvwrapper.sh 保存退出 :wq强制性写入文件并退出。 :x 仅当文件被修改时，写入文件并退出 按esc退出编辑模式，回到命令模式 运行 source ~/.bashrc 此时virtualenvwrapper就可以使用了。 列出虚拟环境列表 workon 也可以使用 lsvirtualenv 新建虚拟环境 mkvirtualenv [虚拟环境名称] 启动/切换虚拟环境 workon [虚拟环境名称] 删除虚拟环境 rmvirtualenv [虚拟环境名称] 离开虚拟环境 deactivate 在创建好了虚拟环境之后需要安装对应的开发中的包，利用虚拟环境中自带的pip命令： pip install -U -r requirements/DEVELOPMENT 在用pycharm中需要配置对应的python的包路径，使用虚拟环境中的包 设置对应的源码，资源文件 设置对应的setting文件 设置django server 配置其中的环境变量：DJANGO_SETTINGS_MODULE=settings.development "},"python/basic/python_partial_wrapper.html":{"url":"python/basic/python_partial_wrapper.html","title":"4.1.5、partial和wrapper的使用","keywords":"","body":"装饰器partial、update_wrapper、wraps作用以及如何使用 在讲解partial、update_wrapper、以及wraps之前需要了解下装饰器：装饰器在实现的时候，被修饰后的函数其实已经是另外一个函数了(函数名等函数属性会发生比变化)。因此，为了不影响，python使用wraps来消除这样的副作用，因此，在我们写装饰器的时候，最好在实现之前加上wraps，它能保留原有函数的属性 1. partial 有什么用？ partial又叫偏函数。函数在执行的时候需要带上必要的参数，有些参数是执行之前就是可知的，这种情况下，一个函数有一个或者多个函数预先就能用上，以便函数能够更少的参数进行调用。 如何使用？ 首先先定义一个函数 def add(x, y): return x + y 然后再利用partial对定义一个新的函数 add1 = partial(add, y=3) # 这里创建了一个新的函数 最后再调用add1 print add1(4) # 7 print add(x=4, y=9) # 13 2. update_wrapper 有什么用？ updatewrapper这个函数的主要功能是负责copy原函数的一些属性，如_moudle、name、doc、等，如果不加update_wrapper,那么被装饰器修饰的函数就会丢失其上面的一些属性信息 如何使用？ 首先定义一个函数 def wrapper(f): def wrapper_function(*args, **kwargs): \"\"\"这个是修饰函数\"\"\" return f(*args, **kwargs) update_wrapper(wrapper_function, f) # 利用装饰器定义一个新的函数 @wrapper def wrapped(): \"\"\"这个是被修饰的函数\"\"\" pass 最后输出被装饰器修饰的函数的信息 print(wrapped.__doc__) # 输出`这个是被修饰的函数` print(wrapped.__name__) # 输出`wrapped` __doc__和__name__属性已经是wrapped函数中的，当然，updatewrapper函数也对__module__和`_dict`等属性进行了更改和更新 3. wraps 有什么作用？ 被装饰器修饰后的函数会编程另外一个函数，为了不受影响，利用wraps来消除这样的副作用，使它能够保持原函数的属性。 如何使用？ 首先先定义一个函数 def wrapper(f): @wraps(f) def wrapper_function(*args, **kwargs): \"\"\"这个是修饰函数\"\"\" return f(*args, **kwargs) return wrapper_function 利用装饰器定义一个新的函数 @wrapper def wrapped(): \"\"\"这个是被修饰的函数 \"\"\" pass 最后输出被装饰器修饰的函数的信息 print(wrapped.__doc__) # 输出`这个是被修饰的函数` print(wrapped.__name__) # 输出`wrapped` ​ ​ "},"python/basic/python_error.html":{"url":"python/basic/python_error.html","title":"4.1.6、python错误解决","keywords":"","body":"python中错误解决 1. Django中的错误解决 启动web的时候的错误为：‘’‘解决：CentOS下的 error while loading shared libraries: libmysqlclient.so.16: cannot open shared object file: No such file or dir’ 原因： 缺少共享库libmysqlclient.so.20，般都是ldconfig 没有找到共享库的位置，或者 软链接的问题 解决办法： 先找到对应的libmysqlclient.so文件，或者下载（如果下载则忽略这一步骤） updatedb locate libmysqlclient.so 到libmysqlclient.so 文件下做一个软连接到/usr/lib ln -s /usr/local/mysql/lib/libmysqlclient.so.20 /usr/lib/libmysqlclient.so.20 ​ ​ ​ "},"python/basic/python_network.html":{"url":"python/basic/python_network.html","title":"4.1.7、python网络编程和多线程","keywords":"","body":"python中socket编程 [TOC] 1. 服务器端为socket方式 服务器端代码如下所示： ```python def service(host, port): sk = socket.socket() sk.bind((host, port)) sk.listen(5) while True: print 'server waiting ..........' # 等待链接,阻塞，直到渠道链接 conn打开一个新的对象 专门给当前链接的客户端 addr是ip地址 con, addr = sk.accept() # 获取客户端请求数据 client_data = con.recv(1024) print str(client_data) # 向对方发送数据 con.sendall('不要回答,不要回答,不要回答') # con.close() if name == \"main\": HOST, PORT = 'localhost', 9991 service(HOST, PORT) * 客户端代码如下所示： ```python def client(ip): sk = socket.socket() sk.connect(ip) time.sleep(4) msg = {'status': True, 'leave': True, 'msg': '我下线了！'} sk.sendall(str(msg)) server_reply = sk.recv(1024) print str(server_reply) print '我下线了' if __name__ == '__main__': address = ('localhost', 9991) client(address) 2. 服务器端为SocketServer方式 服务器端代码如下所示： ```python class MyTcpHandler(SocketServer.BaseRequestHandler): def handle(self): self.data = self.request.recv(1024).strip() print '{} wrote:'.format(self.client_address[0]) print self.data self.request.sendall(self.data.upper()) if name == \"main\": HOST, PORT = \"localhost\", 9999 # Create the server, binding to localhost on port 9999 # ThreadingTCPServer 支持多线程并发 server = SocketServer.ThreadingTCPServer((HOST, PORT), MyTcpHandler) server.serve_forever() * 客户端代码如下所示： ```python def client(): HOST, PORT = \"localhost\", 9999 data = \"mango \" # Create a socket (SOCK_STREAM means a TCP socket) sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) try: # Connect to server and send data sock.connect((HOST, PORT)) sock.sendall(data) # Receive data from the server and shut down received = str(sock.recv(1024)) print received finally: sock.close() if __name__ == '__main__': client() python中的多线程编程 1. python中创建线程的两种方式 1.1 直接调用方式创建线程： 代码如下所示： def say_hi(num): time.sleep(random.randint(0, 5)) print 'running on number: %s' % num time.sleep(3) if __name__ == '__main__': # 生成线程实例 并且启动线程 for index in range(100): threading.Thread(target=say_hi, args=(index,)).start() 1.2 通过继承方式创建线程 代码如下所示： ```python class MyThread(threading.Thread): def __init__(self, num): threading.Thread.__init__(self) self.num = num def run(self): time.sleep(random.randint(0, 3)) print 'the number is %s!' % self.num if name == 'main': for index in range(100): MyThread(index).start() ### 2. python 中join * python 默认参数创建线程后，不管主线程是否执行完毕，都会等待子线程执行完毕才一起退出，有无join结果一样 * 如果创建线程，并且设置了daemon为true，即thread.setDaemon(True), 则主线程执行完毕后自动退出，不会等待子线程的执行结果。而且随着主线程退出，子线程也消亡。 * join方法的作用是**阻塞**，等待子线程结束，join方法有一个参数是timeout，即如果主线程等待timeout，子线程还没有结束，则主线程强制结束子线程。 * 如果线程daemon属性为False， 则join里的timeout参数无效。主线程会一直等待子线程结束。 * 如果线程daemon属性为True， 则join里的timeout参数是有效的， 主线程会等待timeout时间后，结束子线程。此处有一个坑，即如果同时有N个子线程join(timeout），那么实际上主线程会等待的超时时间最长为 timeout， 因为每个子线程的超时开始时刻是上一个子线程超时结束的时刻。 * 代码如下所示： ```python def run(n): print '[%s]---------running--------\\n' % n time.sleep(2) print '----done-----' def main(): for index in range(5): t = threading.Thread(target=run, args=(index,)) t.start() t.join(2) print 'starting thread, the name is %s' % t.getName() if __name__ == '__main__': m = threading.Thread(target=main, args=[]) m.setDaemon(True) # 设置为守护线程,它作为程序的主线程，当主线程退出时,m线程也会退出, 由m启动的其它子线程会同时退出,不管是否执行完任务 m.start() m.join(timeout=3) print(\"---main thread done----\") 3. 锁 3.1 Lock(互斥锁) 用法如下所示： def add_num(): global num print '--get num:%s' % num time.sleep(1) lock.acquire() num -= 1 lock.release() if __name__ == '__main__': num = 101 lock = threading.Lock() thread_list = [] for i in range(100): t = threading.Thread(target=add_num) t.start() thread_list.append(t) for tl in thread_list: # 等待所有线程执行完毕 t.join() print 'final num: %s' % num 3.2 RLock(递归锁) 用法如下所示(在一个大锁中还要再包含子锁)： ```python def run1(): print 'grab the first part data' lock.acquire() global num num += 1 lock.release() return num def run2(): print 'grab the second part data' lock.acquire() global num2 num2 += 1 lock.release() return num2 def run3(): lock.acquire() res = run1() print '-----------between run1 and run2 ----------' res2 = run2() lock.release() print res, res2 if name == 'main': num, num2 = 0, 0 lock = threading.RLock() for i in range(10): t = threading.Thread(target=run3) t.start() while threading.active_count() != 1: print threading.active_count else: print '-----all threads done-------' print num, num2 #### 3.3 信号量(Semaphore) * 互斥锁 同时只允许一个线程更改数据，而Semaphore是同时允许一定数量的线程更改数据 ，比如厕所有3个坑，那最多只允许3个人上厕所，后面的人只能等里面有人出来了才能再进去。(同时对一个全局变量修该数据不准确) * 代码如下所示： ```python # -*- coding: utf-8 -*- # 信号量 # 互斥锁 同时只允许一个线程更改数据，而Semaphore是同时允许一定数量的线程更改数据 ， # 比如厕所有3个坑，那最多只允许3个人上厕所，后面的人只能等里面有人出来了才能再进去。 import threading import time def run(n): semaphore.acquire() time.sleep(1) print 'run the thread: %s \\n' % n semaphore.release() if __name__ == '__main__': num = 0 # 最多允许5个线程同时运行 semaphore = threading.BoundedSemaphore(5) for i in range(20): t = threading.Thread(target=run, args=(i,)) t.start() while threading.active_count() != 1: pass # print threading.active_count() else: print('----all threads done---') print(num) 3.4 多线程交互(Event) 在python多线程的环境下，threading.Event默认内置了一个标志，初始值为False，该线程通过wait()方法或者clear()方法进入等待状态，直到一个线程调用该Event的set()方法将内置标识设置为True的时候，该Event会通知所有等待状态的线程恢复运行。 下面代码模拟红绿灯的例子： ```python -- coding: utf-8 -- 通过Event来实现两个或多个线程间的交互 下面是一个红绿灯的例子 import random import threading import time def light(): if not event.isSet(): event.set() count = 0 while True: if count def car(n): while True: time.sleep(random.randrange(10)) if event.isSet(): # 绿灯 print \"car [%s] is running..\" % n else: print \"car [%s] is waiting for the red light..\" % n if name == 'main': event = threading.Event() light = threading.Thread(target=light) light.start() for i in range(4): threading.Thread(target=car, args=(i,)).start() ``` ​ "},"python/django/readme.html":{"url":"python/django/readme.html","title":"4.2、Django框架","keywords":"","body":""},"python/django/django_create.html":{"url":"python/django/django_create.html","title":"4.2.1 Django项目的创建","keywords":"","body":"django创建虚拟环境、自定义用户、用户拦截以及项目的搭建 项目地址：mangoD 1. 创建虚拟环境 在创建虚拟环境之前先说下虚拟环境的作用： pyhton虚拟环境可以使python程序拥有独立的库和解释器，不和其他的程序共享，避免了不同python程序的相互的影响。 用户也可以直接在安装了python的环境中安装django框架 pip install django 现在来说说怎样在centos中安装虚拟环境 首先先安装virtualenv以及virtualenvwrapper模块，命令如下所示： sudo pip install virtualenv sudo pip install virtualenvwrapper 然后再创建虚拟环境的目录并且配置环境变量 mkdir /home/your/.virtualenv # 其中.virtualenv可以是其他的名字只要与环境变量中的对应就可以了 vi /home/your/.bashrc 在.bashrc文件中添加一下语句 export WORKON_HOME=/home/your/.virtualenvs export VIRTUALENVWRAPPER_SCRIPT=/usr/local/bin/virtualenvwrapper.sh source /usr/bin/virtualenvwrapper.sh 保存并退出：wq 运行 source /home/your/.bashrc 此时virtualenvwrapper就可以使用了，常用命令： 创建虚拟环境 mkvirtualenv envname # 其中envname就是你需要创建的虚拟环境的名字 切换环境： workon envname 列出已有的环境： workon 退出环境 deactivate 删除环境 rmvirtualenv 安装好了虚拟环境之后我们需要创建一个虚拟环境mkvirtualenv mango，在/home/your/.virtualenvs我们可以看到一个文件夹mango，这个文件夹就是我们的虚拟环境的目录 然后我们需要切换到刚刚创建的mango环境中： workon mango 然后我们需要安装django，pip install Django==1.11 在这个步骤我们可以将需要安装的包写在一个文件(requrement)中， 在文件中的包有： Django==1.11 MysqL-python==1.2.5 然后通过命令pip install -U -r requrement就会自动将文件中的包安装好 接下来就需要我们创建自己的项目了 2. 创建项目 打开pycharm（也可以是其他的IDE），点击file->New Project，此时会弹出一个创建项目的弹出框，在左边选择Django，在右边选择对应的目录（在选择的时候就创建一个文件夹作为项目路径和项目名称mangoDJ）， 然后选择对应的python环境，选择刚刚创建的mango的虚拟环境的目录 对应的目录结构如下所示： 创建apps文件夹，将apps文件夹设置为源文件夹（点击项目mangoDJ右键mark Directory as ->source Root），之后将所有创建的app都放在该文件夹下面，并且在settings.py中添加如下代码： sys.path.insert(0,os.path.join(BASE_DIR,'apps')) 将templates标记为Template Folder(点击项目mangoDJ右键mark Directory as ->Template Folder) 配置启动环境： 配置环境所需要的库文件：分别在setting和default setting中配置 然后再右上角点击edit configration，添加django serevr，并且配置对应的端口号。 创建app 使用命令python manager startapp account创建account模块，并将account放在apps文件夹下面,并且在setting.py中的INSTALLED_APPS添加account(每创建一个app最好都放在apps文件夹下面) 在使用命令python manager startapp web创建web模块，并将web放在apps文件夹下面,并且在setting.py中的INSTALLED_APPS添加web 在使用命令python manager startapp common创建common模块，并将common放在apps文件夹下面,并且在setting.py中的INSTALLED_APPS添加common 在项目mangoDJ下创建static文件夹用于存放静态资源 在setting.py中配置如下信息： # URL to use when referring to static files located in STATIC_ROOT. STATIC_URL = '/static/' # Additional locations the staticfiles app will traverse if the # FileSystemFinder finder is enabled. STATICFILES_DIRS = ( BASE_DIR / 'static', ) 配置这些信息可以访问到静态资源 3. 配置文件编辑 配置setting.py文件，主要配置数据库， 缓存等信息 数据库配置的格式： DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': 'mango', # Or path to database file if using sqlite3. 'USER': 'root', 'PASSWORD': 'root', 'HOST': '127.0.0.1', 'PORT': '3306', # Set to empty string for default. }, } 配置缓存(根据自己的情况可要可不要) CACHES = { \"default\": { \"BACKEND\": \"django_redis.cache.RedisCache\", \"LOCATION\": \"redis://172.0.0.1:6379/1\", \"OPTIONS\": { \"CLIENT_CLASS\": \"django_redis.client.DefaultClient\", } } } 4. 用户请求拦截 在配置用户请求拦截的时候需要在配置文件中配置对应的 LOGIN_URL = '/user/login', LOGOUT_URL = '/logout' 在common模块中创建require.py,并且添加如下代码（也可以参考这篇文章）： # -*- coding: utf-8 -*- def required(wrapping_functions, patterns_rslt): if not hasattr(wrapping_functions, '__iter__'): wrapping_functions = (wrapping_functions,) return [ _wrap_instance__resolve(wrapping_functions, instance) for instance in patterns_rslt ] def _wrap_instance__resolve(wrapping_functions, instance): if not hasattr(instance, 'resolve'): return instance resolve = getattr(instance, 'resolve') def _wrap_func_in_returned_resolver_match(*args, **kwargs): rslt = resolve(*args, **kwargs) if not hasattr(rslt, 'func'): return rslt f = getattr(rslt, 'func') for _f in reversed(wrapping_functions): # @decorate the function from inner to outter f = _f(f) setattr(rslt, 'func', f) return rslt setattr(instance, 'resolve', _wrap_func_in_returned_resolver_match) return instance 在urls.py中添加如下配置（一定要写在登陆url之前）： urlpatterns += required( partial(login_required, login_url='user_login'), urlpatterns ) urlpatterns += [ url(r'user/login', web.view_home.login, name='user_login'), ] ​ 5. 用户自定义编写 在account模块中models.py编写自定义用户实体，需要在setting.py中配置实体类代码如下所示 AUTH_USER_MODEL = 'account.Account' 编写实体： 创建AccountManager class AccountManager(BaseUserManager): def _create_user(self, username, password, is_staff, is_active, **extra_fields): if username: raise ValueError(\"the input username is error\") if password: raise ValueError(\"the input password is error\") user = self.model(username=username, password=password, is_staff=is_staff, is_active=False, **extra_fields) user.save(self._db) return user def create_user(self, username, password, **extra_fields): return self._create_user(self, username=username, password=password, is_staff=False, is_active=False, **extra_fields) def create_superuser(self, username, password, **extra_fields): return self._create_user(self, username=username, password=password, is_staff=True, is_active=True, **extra_fields) 创建AbstractUser： class AbstractUser(AbstractBaseUser, PermissionsMixin): # 用户名称 username = models.CharField(unique=True, max_length=30) # password = models.CharField(max_length=20, null=False, default='123456') is_staff = models.BooleanField(_('staff status'), default=False) is_active = models.BooleanField(_('active'), default=True) USERNAME_FIELD = 'username' REQUIRED_FIELDS = [] objects = AccountManager() class Meta(object): db_table = 'account' abstract = True def get_short_name(self): return self.get_username() def get_full_name(self): return self.get_username() 创建Account： class Account(AbstractUser): nick_name = models.CharField(max_length=30, default='') # login_date = models.DateTimeField(auto_now_add=True, editable=False, blank=True) class Meta(AbstractUser.Meta): permissions = ( ('person:info', '我的面板:个人信息'), ('person:modify-pwd', '我的面板:修改密码'), ('user:list', '平台用户管理:用户帐号管理'), ('user:score-manage', '用户管理:积分账户管理'), ) swappable = 'AUTH_USER_MODEL' 自定义用户认证，在setting配置对应的认证的类，如下： # -*- coding: utf-8 -*- from django.contrib.auth.backends import ModelBackend from django.db.models import Q from account.models import Account class AccountBackend(ModelBackend): def authenticate(self, username=None, password=None, **kwargs): try: user = Account.objects.get(Q(username=username)) if user.password == password: return user except Account.DoesNotExist: return None return None ​ 在配置文件中配置自定义的权限认证的类： AUTHENTICATION_BACKENDS = ( 'common.account_backend.AccountBackend', ) 对应的项目地址为：mangoDJ "},"python/django/django_user.html":{"url":"python/django/django_user.html","title":"4.2.2 Django配置用户拦截请求","keywords":"","body":"1. 拦截用户的请求的示列（1）： 示列代码： def required(wrapping_functions,patterns_rslt): ''' Used to require 1..n decorators in any view returned by a url tree Usage: urlpatterns = required(func,patterns(...)) urlpatterns = required((func,func,func),patterns(...)) Note: Use functools.partial to pass keyword params to the required decorators. If you need to pass args you will have to write a wrapper function. Example: from functools import partial urlpatterns = required( partial(login_required,login_url='/accounts/login/'), patterns(...) ) ''' if not hasattr(wrapping_functions,'__iter__'): wrapping_functions = (wrapping_functions,) return [ _wrap_instance__resolve(wrapping_functions,instance) for instance in patterns_rslt ] def _wrap_instance__resolve(wrapping_functions,instance): if not hasattr(instance,'resolve'): return instance resolve = getattr(instance,'resolve') def _wrap_func_in_returned_resolver_match(*args,**kwargs): rslt = resolve(*args,**kwargs) if not hasattr(rslt,'func'):return rslt f = getattr(rslt,'func') for _f in reversed(wrapping_functions): # @decorate the function from inner to outter f = _f(f) setattr(rslt,'func',f) return rslt setattr(instance,'resolve',_wrap_func_in_returned_resolver_match) return instance 其中的login_required可以换成其他的修饰器。 使用： urlpatterns += required( partial(login_required,login_url='/accounts/login/'), urlpatterns ) ​ 参考地址：https://www.91r.net/ask/9318962.html 2.拦截用户请求的示列(2): 示列代码： from django.core.urlresolvers import RegexURLPattern, RegexURLResolver from django.conf.urls.defaults import patterns, url, include from django.contrib import admin from myproject.myapp.decorators import superuser_required class DecoratedURLPattern(RegexURLPattern): def resolve(self, *args, **kwargs): result = super(DecoratedURLPattern, self).resolve(*args, **kwargs) if result: result.func = self._decorate_with(result.func) return result class DecoratedRegexURLResolver(RegexURLResolver): def resolve(self, *args, **kwargs): result = super(DecoratedRegexURLResolver, self).resolve(*args, **kwargs) if result: result.func = self._decorate_with(result.func) return result def decorated_includes(func, includes, *args, **kwargs): urlconf_module, app_name, namespace = includes for item in urlconf_module: if isinstance(item, RegexURLPattern): item.__class__ = DecoratedURLPattern item._decorate_with = func elif isinstance(item, RegexURLResolver): item.__class__ = DecoratedRegexURLResolver item._decorate_with = func return urlconf_module, app_name, namespace 使用： urlpatterns = patterns('', # ... (r'^private/', decorated_includes(login_required, include(private.urls))), ) "},"python/django/django_code.html":{"url":"python/django/django_code.html","title":"4.2.3 Django源码解读","keywords":"","body":"Django源码分析--------程序启动入口 本文章的源码分析(程序启动入口)的段落包括：1. 分析之前（创建demo项目）、2. 程序启动入口分析 1. demo的创建 在对源码进行分析之前，先创建一个django项目，创建django的项目的命令如下所示： django-admin startproject demo 创建之后的目录结构如下所示： ├── demo │ ├── __init__.py │ ├── settings.py │ ├── urls.py │ └── wsgi.py └── manage.py 其中django的后台进程通常通过命令python manager.py [options]运行的，其中options为相关的命令（runserver、makemigrations等等），接下来分析manager.py的具体的执行流程 2. 程序启动入口分析 manager.py文件的分析，其中，manager.py的代码如下所示： #!/usr/bin/env python import os import sys if __name__ == \"__main__\": os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"demo.settings\") try: from django.core.management import execute_from_command_line except ImportError: try: import django except ImportError: raise ImportError( \"Couldn't import Django. Are you sure it's installed and \" \"available on your PYTHONPATH environment variable? Did you \" \"forget to activate a virtual environment?\" ) raise execute_from_command_line(sys.argv) 其中，代码os.environ.setdefaul...为设置默认的环境变量，环境变量名称为DJANGO_SETTINGS_MODULE;代码execute_from_command_line方法用于读取命令行参数，并执行相关代码 进入execute_from_command_line方法，该方法的源代码如下所示： def execute_from_command_line(argv=None): \"\"\" A simple method that runs a ManagementUtility. \"\"\" utility = ManagementUtility(argv) utility.execute() 从代码中可以看出，execute_from_command_line可以直接使用utility = ManagementUtility(argv).execute()替换，最终执行的是ManagementUtility中的execute方法。 进入execute方法 在进入execute之后，需要获取对应命令参数(runserver),然后解析命令，设置配置路径以及python路径(如果没有设置，则设置默认的配置)，对应的代码如下所示： try: subcommand = self.argv[1] except IndexError: subcommand = 'help' parser = CommandParser(None, usage=\"%(prog)s subcommand [options] [args]\", add_help=False) parser.add_argument('--settings') parser.add_argument('--pythonpath') parser.add_argument('args', nargs='*') # catch-all 紧接着获取setting中的app, 对应的代码为： try: settings.INSTALLED_APPS except ImproperlyConfigured as exc: self.settings_exception = exc 其中settings引入对应的文件django.conf._init_.py, 在该文件中声明了settings = LazySettings(), LazySettings也在该文件中，在执行settings.INSTALLED_APPS代码的时候，会执行LazySettings中的__getattr方法，该方法的代码如下所示： ```python def __getattr__(self, name): \"\"\" Return the value of a setting and cache it in self.__dict__. \"\"\" if self._wrapped is empty: self._setup(name) val = getattr(self._wrapped, name) self.__dict__[name] = val return val ``` * 在``_setup``中将会先获取之前设置的``DJANGO_SETTINGS_MODULE``环境变量，如果不存在则会抛出异常，如果存在，则继续执行 "},"python/django/django_error.html":{"url":"python/django/django_error.html","title":"4.2.4 Django遇到的问题","keywords":"","body":"Django常遇到的问题 1. django中save()无法立即保存？ 在进行数据库的配置的时候，在数据库的设置了ATOMIC_REQUESTS为True，代码如下所示： DATABASES = { 'default': { 'ENGINE': 'django.db.backends.postgresql_psycopg2', 'NAME': '', 'USER': '', 'PASSWORD': '', 'HOST': '', 'PORT': '', 'ATOMIC_REQUESTS': True, } } 设置了ATOMIC_REQUESTS为True，则表示每个view都会开启事务。 解决办法，在对应的view中使用修饰器@transaction.non_atomic_requests 修饰，表示不是用事务 "},"python/python_operation/readme.html":{"url":"python/python_operation/readme.html","title":"3.3 Python运维","keywords":"","body":""},"python/python_operation/ansible_basic.html":{"url":"python/python_operation/ansible_basic.html","title":"3.4.1 ansible模块介绍","keywords":"","body":"Ansible模块介绍 1. Ansible 1.1 简介 Ansilbe是一个部署一群远程主机的工具。远程的主机可以是远程虚拟机或物理机， 也可以是本地主机。 Ansilbe通过SSH协议实现远程节点和管理节点之间的通信。理论上说，只要管理员通过ssh登录到一台远程主机上能做的操作，Ansible都可以做到。 包括： 拷贝文件 安装软件包 启动服务 … 2. Playbook简介 Ansible的任务配置文件被称之为“playbook”，我们可以称之为“剧本”。每一出剧本（playbook）中都包含一系列的任务，这个任务在ansible中又被称为一出“戏剧”(play)。一个剧本（playbook）中包含多出戏剧(play)。 2.1 Playbook语法简介 Playbook采用一种可读性强而且容易被阅读的YAML语法编写，格式如下 house: family: name: Doe parents: - John - Jane children: - Paul - Mark - Simone address: number: 34 street: Main Street city: Nowheretown zipcode: 12345 3. Playbook实战 4.1 Shell脚本与Playbook的转换 现在越来越多的DevOps开始将目光转向Ansible，Ansible可以轻松的将shell脚本或简单的shell命令转换为Ansible Plays 下面是安装apache的shell脚本： #!/bin/bash # 安装Apache yum install --quiet -y httpd httpd-devel # 复制配置文件 cp /path/to/config/httpd.conf /etc/httpd/conf/httpd.conf cp /path/to/httpd-vhosts.conf /etc/httpd/conf/httpd-vhosts.conf # 启动Apache，并设置开机启动 service httpd start chkconfig httpd on 将shell转换为playbook之后如下所示： --- - hosts: all tasks: - name: \"安装Apache\" command: yum install --quiet -y httpd httpd-devel - name: \"复制配置文件\" command: cp /tmp/httpd.conf /etc/httpd/conf/httpd.conf command: cp /tmp/httpd-vhosts.conf /etc/httpd/conf/httpd-vhosts.conf - name: \"启动Apache，并设置开机启动\" command: service httpd start command: chkconfig httpd on 将以上playbook的内容存放为playbook.yml的文件，直接调用ansible-playbook命令，即可运行，运行结果和脚本一致： # ansible-playbook ./playbook.yml 其他Ansible内置的模块如下所示“： --- - hosts: all sudo: yes tasks: - name: 安装Apache yum: name= state=present with_items: - httpd - httpd-devel - name: 复制配置文件 copy: src: \"\" dest: \"\" owner: root group: root mode: 0644 with_items: - { src: \"/tmp/httpd.conf\", dest: \"/etc/httpd/conf/httpd.conf\" } - { src: \"/tmp/httpd-vhosts.conf\", dest: \"/etc/httpd/conf/httpd-vhosts.conf\" } - name: 检查Apache运行状态，并设置开机启动 service: name=httpd state=started enabled=yes 3.2. Playbook案例解析 剖析以上案例： 第一行，”----“这个是YAML语法中注释的方法，就想shell脚本中的”#“号一样 第二行，”-host:all“，告诉ansible具体在哪些主机上运行我的脚本 第三行，”sudo:yes“，告诉ansible通过sudo来运行命令，这样命令将会以root的身份来运行 第四行，”tasks“,指定一系列要运行的任务 每一个任务（play）以“- name: 安装Apache”开头。“- name:”字段并不是一个模块，不会执行任务实质性的操作，它只是给“task” 一个易于识别和名称。即便把name字段对应的行完全删除，也不会有任何问题。 本例中我们使用yum模块来安装Apache，替代了“yum -y install httpd httpd-devel” 在每一个play当中，都可以例用 with_items 来定义变量，并通过“”的形式来直接使用使用yum模块的state=present选项来确保软件被安装，或者使用state=absent来确保软件被删除 第二个任务（play）同样是“- name”字符开头 我们使用copy模块来将“src”定义的源文件（必须是ansible所在服务器上的本地文件 ）复制到“dest”定义的目的地址（此地址为远程主机的上地址）去,在传递文件的同时，还定义了文件的属主，属组和权限 这个play中，我们用数组的形式给变量赋值，使用{var1: value, var2: value} 的格式来赋值，变量的个数可以任意多，不同变量间以逗号分隔，使用的形式来调用变量，本例中为： 第三个任务（play）使用了同样的结构，调用了service模块，以保证服务的正常开启 3.3 Playbook与shell脚本的差异比较 当我们把shell脚本转换为playbook运行地时候，ansible会留下清晰的执行痕迹，明确报告我们在每一台主机都做了什么 当我们重复执行一个playbook时，当ansible发现系统现有状态符合playbook所定义的状态时，ansible会自动跳过该操作。shell会重复执行。 4. Ansible-playbook命令详解 4.1 限定命令执行范围 --limit 我们可以通过-hosts：字段来指定哪些主机将会被应用到playbook的操作 我们也可以通过如下的命令来指定主机(仅对webservers生效)： # ansible-playbook playbook.yml --limit webservers 4.2 用户与权限设置 --remote-user Playbook中，如果在与hosts同组的字段中没有定义user，那么Ansible将会使用你在inventory文件中定义的用户，如里inventory文件中也没定义用户，Ansible将默认使用当前系统用户身份来通过SSH连接远程主机，在运程程主机中运行play内容。 我们也可以直接在ansible-playbook中使用 --remote-user选项来指定用户： # ansible-playbook playbook.yml --remote-user=tom ​ "},"python/python_operation/python_op.html":{"url":"python/python_operation/python_op.html","title":"3.4.2 python运维模块介绍","keywords":"","body":"python运维常用的模块介绍 1. psutil(系统性能信息模块) 能够轻松实现获取系统运行的进程和系统利用率（包括CPU、内存、磁盘、网络等）信息。它主要应用于系统监控，分析和限制系统资源及进程的管理。它实现了同等命令行工具提供的功能，如ps、top、lsof、netstat、ifconfig、who、df、kill、free、nice、ionice、iostat、iotop、uptime、pidof、tty、taskset、pmap等。目前支持32位和64位的Linux、Windows、OS X、FreeBSD和Sun Solaris等操作系统。 2. IPy(IP地址处理模块) IP地址规划的好坏直接影响路由协议算法的效率，包括网络性能、可扩展性等方面，在这个过程中，需要计算大量的IP地址，包括网段、网络掩码、广播地址、子网数、IP类型等。Python提供了IPy模块帮助我们完成IP地址规划。 3. dnspython(DNS处理模块) 在系统管理方面，我们可以利用其查询功能来实现DNS服务监控以及解析结果的校验。 4. smtplib(电子邮件模块) 5. XlsxWriter(EXcel操作模块) "},"algorithm/readme.html":{"url":"algorithm/readme.html","title":"第五部分 数据结构与算法","keywords":"","body":""},"algorithm/word.html":{"url":"algorithm/word.html","title":"5.1、算法中常用的名词解释","keywords":"","body":"线性查找 线性查找又称顺序查找，是一种最简单的查找方法，它的基本思想是从第一个记录开始，逐个比较记录的关键字，直到和给定的K值相等，则查找成功；若比较结果与文件中n个记录的关键字都不等，则查找失败。 循环不变式 循环不变式是一种证明程序(循环)正确性的写法，包含有三个特性。如果在循环的每一步这个式子都正确，那么循环结束后，这个式子也正确。 初始化：在循环的第一轮迭代前是正确的 保持：如果在循环的某一次迭代开始之前是正确的，那么在下一次迭代开始之前，也是正确的 终止：当循环结束，不变式给了我们一个有用的性质。 分治法： 思想 将原问题分解为几个规模较小但类似于原问题的子问题，递归的求解这些子问题，然后合并这些子问题的解来建立原问题的解。 步骤 分解：原问题为若干子问题，这些子问题是原问题的规模较小的实例。 解决：递归的求解各子问题。然而，若子问题的规模够小，则直接求解。 合并：这些子问题的解成原问题的解。 "},"algorithm/encryption_algorithm.html":{"url":"algorithm/encryption_algorithm.html","title":"5.2、加密算法","keywords":"","body":"对称加密以及非对称加密中常见的算法 1. 对称加密以及非对称加密的比较 比较 对称加密 非对称加密 介绍 对称加密指的是加密和解密使用的是同一个密钥 加密和揭秘使用的不同的密钥，一把作为公开的公钥，另外一把作为私钥。公钥加密的信息只有私钥才能解密，私钥加密的信息只有公钥才能解密。 常见的算法 DES、AES、3EDS等等 RSA、ECC 区别 加密效率高、密钥容易泄露 加密效率低、安全 在实际我们可以同时使用对称加密以及非对称机密 在C/S模型中，服务器端计算出一对密钥pub/pri.将私钥保密，将公钥公开。 客户端请求服务器端的时候，拿到服务器端的公钥pub。 客户端通过AES计算出一个对称加密的密钥X。然后使用pub将X进行加密。 客户端将机密之后的密文发送给服务器端。服务器通过pri解密获得X。 然后两边的通信内容就通过对称密钥以对称加密算法来解密。 2. 加密密钥中常见的比较 名称 密钥长度 运算速度 安全性 资源消耗 DES 56位 较快 低 中 3DES 112或168位 慢 中 高 AES 128、192、256 快 高 低 3. 非对称加密常见的比较 名称 成熟度 运算速度 安全性(取决于密钥长度) 资源消耗 RSA 高 慢 高 高 DSA 高 慢 高 只能用于数字签名 ECC 低 快 高 低(计算量小，存储空间小) 4. 散列算法比较 适用于数据库中密码的存放、防止信息在传输过程中被篡改 名称 安全性 速度 SHA-1 高 慢 MD5 中 快 "},"database/basic/readme.html":{"url":"database/basic/readme.html","title":"6.1、数据库基础","keywords":"","body":""},"database/basic/pool.html":{"url":"database/basic/pool.html","title":"数据库连接池","keywords":"","body":"连接池的作用： 连接池的是将创建好的连接存放在池中，当有请求来的时候，直接使用连接池中已经创建好的连接对数据库进行访问，这样节省了连接数据库的时间以及开销。 连接池的创建过程： c3p0创建的三种方式（读取信息的方式）：直接赋值、从properties文件中加载、从xml文件中加载 "},"database/mysql/readme.html":{"url":"database/mysql/readme.html","title":"6.2、MySQL数据库","keywords":"","body":""},"database/mysql/mysql_basic.html":{"url":"database/mysql/mysql_basic.html","title":"6.2.1 MySQL基础","keywords":"","body":"1.mysql适用场景？ web网站系统 日志记录系统 数据仓库系统 嵌入式系统 2.日志文件 2.1 错误日志：Error Log 错误日志记录Mysql Server运行过程中的较为严重的警告和错误信息，以及Mysql Server每次启动和关闭的详细信息。一般系统是默认关闭的，如需开启，在启动的时候开启-log-error选项。错误日志存放在数据目录下。 2.2 二进制日志 当开启二进制日志的时候，Mysql会将所有修改数据库的query以二进制形式记录到日志文件中。其中还包含每一条query所执行的时间，消耗的资源，以及相关事务信息，因此二进制日志是事务安全的。 2.3 查询日志 查询日志记录Mysql中所有的query，开启之后会对性能有比较大的影响。 2.4 慢查询日志 慢查询日志中记录的是执行时间较长的query，也就是我们常说的slow query。默认的文件名为hostname-slow.log 2.5 Innodb的在线redo日志 3. 数据文件 在mysql中每一个数据库都会定义好（或者默认）的数据目录下存在一个数据库名字相同的文件夹，用来存放该数据库中的各种表数据文件。不同的Mysql存储引擎有个字不同的数据库文件，存放位置也有区别。 3.1 “.frm”文件 与表相关的元数据（meta）信息都存放在\".frm\"文件中，包括表结构的定义信息等。不论是什么存储引擎，每一个表都会有这个文件。并且存储在数据库文件夹下面。 3.2 \".MYD\"文件 \".MYD\"文件是MyISAM存储引擎专用，存放MyISAM表的数据。每一个MyISAM表都会有一个\".MYD\"文件与之对应，同样存放于数据库文件夹下面。 3.3 “.MYI”文件 “.MYI”文件也属于MyISAM存储引擎的，主要存放MyISAM表的索引相关信息。同样，每一个MyISAM文件对应一个“.MYI”文件。 3.4 “.ibd”文件和ibdata文件 这两个文件都是存放Innodb数据的文件，之所以有两种文件存放的数据（包含索引），是因为Innodb的数据存储方式能够通过配置来决定是使用共享表空间存储数据还是独享表空间存放存储数据。独享表空间存储使用“.ibd”文件来存储，且每一个表对应一个\".ibd\"文件。如果是共享表空间，则会使用ibdata文件存储，所有的表共同使用一个或者多个。 4 逻辑模块组成 MySQL可以看成是两层架构，第一层我么通常叫做SQL Layer，在MySQL数据库系统处理底层数据之前的所有工作都是有这一层完成的，包括权限的哦安段，sql解析，执行计划优化，query cache的处理等等；第二层就是存储引擎层，我们通常叫做Storage Engine Layer，也就是底层数据存取操作实现部分，由多种存储引擎共同组成。 初始化模块 初始化模块就是在MySQL Server启动的时候，对整个系统做各种各样的初始化操作，比如各种buffer，cache结构的初始化以及内存空间的申请，各种系统变量的初始化设定，各种存储引擎的初始化设置等等。 核心API 核心API模块主要是为了提供一些需要非常高效的底层操作功能的优化实现，包括各种底层数据结构的实现，特殊算法的实现，字符串处理，数字处理等，小文件I/O，格式化输出，以及重要的内存管理部分。核心API模块的所有源代码都集中在mysys和strings文件夹下。 网络交互模块 底层网络交互模块抽象出底层网络交互所使用的接口api，实现底层网络数据的接收与发送，以方便其他各个模块调用，以及对这一部分的维护。所有源码都在vio文件夹下。 Client&Server交互协议模块 任何C/S结构的软件系统都会有自己独有的信息交互协议。Mysql的Client&Server交互协议模块部分实现了客户端与Mysql交互过程中的所有的协议。 用户模块 用户模块所实现的功能主要包括用户的登陆连接权限控制和用户的授权管理。 访问控制模块 根据用户模块中各个用户的授权信息，以及数据库自身特有的各种约束，来控制用户对数据的访问。 连接管理、连接线程和线程管理 连接管理模块负责监听对MySQL Server的各种请求，接收连接请求，转发所有连接请求到线程管理模块。每一个连接上MySQL Server的客户端请求都会被分配（创建）一个连接线程为其单独服务。 连接线程负责MySQL Server与客户端的通信，接受客户端的命令请求，传递Server端的结果信息等。 线程管理模块负责维护这些连接线程。 Query解析和转发模块 Query Cache模块 Query优化器模块 表变更管理模块 表维护模块 系统状态管理模块 表管理模块 日志记录模块 复制模块 存储引擎接口模块 各个模块之间的关系如下所示： 执行流程 "},"database/mysql/mysql_error.html":{"url":"database/mysql/mysql_error.html","title":"6.2.2 MySQL常见错误","keywords":"","body":"Mysql常见的错误 1. 在使用timestamp类型的时候设置了默认值‘0000-00-00 00:00:00’发生异常 Invalid default value for 'updateTime'？ 原因： timestamp的取值范围为 1970-01-01 00:00:00 到 2037-12-31 23:59:59 "},"database/redis/readme.html":{"url":"database/redis/readme.html","title":"6.3、Redis数据库","keywords":"","body":""},"database/redis/redis_basic.html":{"url":"database/redis/redis_basic.html","title":"redis数据库基础","keywords":"","body":"1. redis的存储结构 redis是（Remote Dictionary Server：远程字典服务器）的缩写，它以字典结构存储数据，并且允许其他应用通过tcp协议读写字典中的内容。redis字典的键值除了可以是字符串，还可以是其他的数据类型。redis支持的数据结构类型输入下所示： 字符串类型 散列类型 列表类型 集合类型 有序集合类型 2.内存存储与持久化 redis数据库中的所有数据都存储在内存中。由于内存的读写速度远远快于硬盘，因此redis在性能上对比其他基于硬盘存储的数据库有非常明显得优势，在普通的笔记本电脑中，redis可以在一秒内读写超过十万个键值。 redis提供了持久化的支持，在内存中的数据会异步的些图硬盘中，同时不会影响服务。 3.redis与memcached的区别？ redis是单线程模型。而memcached是支持多线程。在多核服务器上后者性能更高 4. "},"database/db_optimization.html":{"url":"database/db_optimization.html","title":"数据库优化","keywords":"","body":"数据库优化 1. 关系型数据库的优化 1.1. 优化工具介绍 常用的优化工具 常用的数据库优化工具有EXPLAIN等等 1.2. EXPLAIN介绍 如何使用？ 使用的方式为： explain + 查询的sql语句 EXPLAIN SELECT IF (a. STATUS = 1,(w.remark),(a.remark)) remark,a.type, a.created,merchant.nickname AS merchant_nickname, account_from.username AS merchant_name,FROM account_bill a LEFT JOIN wallet_cash_flow w ON w.bill_id = a.id LEFT JOIN wallet w_from ON (w_from.id = w.from_wallet_id) LEFT JOIN wallet w_to ON (w_to.id = w.to_wallet_id) INNER JOIN account merchant ON merchant.id = a.merchant_id LEFT JOIN account account_from ON account_from.id = w_from.account_id LEFT JOIN account account_to ON account_to.id = w_to.account_id 返回的结果 将会返回对应表的分析，如下图所示： 返回的结果分析 id：select识别符。这是select查询的序列号（也就是sql语句执行的顺序） select_type： select类型，它有以下几种值 simple：表示简单的select，没有union和子查询 primary：最外面的select在有子查询的语句中，最外面的查询就是primary union：union语句第二个或者说是最后一个 dependent union：union中的第二个或后面的SELECT语句，取决于外面的查询 union result：union的结果 table：显示这一行的数据是关于哪一张表的 type：连接类型，有多个参数（重要） system：表仅有一行，这是const类型的特列 const：表最多有一个匹配行，const用于比较primary key或者unique索引。因为只匹配一行数据，所以查询很快，也是最优的。 eq_ref ：对于每个来自于前面的表的行组合，从该表中读取一行。这可能是最好的联接类型，除了const类型。它用在一个索引的所有部分被联接使用并且索引是UNIQUE或PRIMARY KEY ref：对于每个来自前面的表的组合，所有有匹配的值的行将从这张表中读取。如果使用的键仅仅匹配少量行，该连接类型是不错的。 ref_or_null：该连接类型如同ref，但是添加了MySQL可以专门搜索包含NULL值得行，在解决子查询中经常使用到。 以上五种情况都是理想的情况 index_merge：该连接类型表示使用了索引合并优化方法。在这种情况下，key列包含了使用索引的清单，key_len包含了使用索引的最长的关键元素。 unique_subquery index_subquery range 给定范围内的检索，使用一个索引来检查行 index 该联接类型与ALL相同，除了只有索引树被扫描。这通常比ALL快，因为索引文件通常比数据文件小。 ALL 对于每个来自于先前的表的行组合，进行完整的表扫描。 possible_keys：提示使用哪个索引会在该表中找到行 key： MYSQL使用的索引，简单且重要 key_len： MYSQL使用的索引长度 ref ：ref列显示使用哪个列或常数与key一起从表中选择行。 rows ：显示MYSQL执行查询的行数，简单且重要，数值越大越不好，说明没有用好索引 Extra ：该列包含MySQL解决查询的详细信息 Distinct MySQL发现第1个匹配行后，停止为当前的行组合搜索更多的行 Not exists range checked for each record：没有找到合适的索引 using filesort：MySQL需要额外的一次传递，以找出如何按排序顺序检索行。通过根据联接类型浏览所有行并为所有匹配WHERE子句的行保存排序关键字和行的指针来完成排序。然后关键字被排序，并按排序顺序检索行。 using index：只使用索引树中的信息而不需要进一步搜索读取实际的行来检索表中的信息。这个比较容易理解，就是说明是否使用了索引 using temporary：为了解决查询，MySQL需要创建一个临时表来容纳结果。典型情况如查询包含可以按不同情况列出列的GROUP BY和ORDER BY子句时。出现using temporary就说明语句需要优化了 2.非关系型数据库优化 "},"network/readme.html":{"url":"network/readme.html","title":"第七部分 计算机网络","keywords":"","body":""},"network/network_basic.html":{"url":"network/network_basic.html","title":"7.1、计算机网络基础","keywords":"","body":"基础网络知识 1. 如何访问内网中的电脑？ 利用路由器的端口映射。在外网访问内网中的电脑，无非就是想访问电脑的某个端口，可以通过(路由器IP(外网IP)：外网端口：内网电脑IP(192.168.1.1):内网端口)，通过以上四个参数就可以唯一标识内网电脑中的网络端口。 "},"network/TCPIP/readme.html":{"url":"network/TCPIP/readme.html","title":"7.2、图解TCP/IP","keywords":"","body":""},"network/TCPIP/chapter1.html":{"url":"network/TCPIP/chapter1.html","title":"7.2.1、计算机网络基础","keywords":"","body":"1.1 计算机网络出现的背景 计算机网络按照规模划分可以划分为WAN（广域网）、LAN（局域网） WAN指覆盖多个远距离区域的远程网络。比广域网在小一级的、连接整个城市的叫做城域网。 局域网指一个楼层、一栋或一个校园等相对较小的区域内的网络。 1.2计算机网络发展的七个阶段 年代 内容 20世纪50年代 批处理时代 20世纪60年代 分时系统时代 20世纪70年代 计算机间通信时代 20世纪80年代 计算机网络时代 20世纪90年代 互联网普及时代 2000年 以互联网为中心时代 2010年 无论何时何地皆以TCP/IP的网络时代 1.3 协议 1.3.1 CPU、OS以及内核的作用？ CPU为中央处理器，如同一个计算机的心脏，每个程序实际上是由它来进行调度执行的。CPU的性能很大的程度上决定着一台计算机的处理性能。 OS为操作系统，是一种基础软件，集合了CPU管理、内存管理、计算机的外围设备管理以及程序运行管理等重要功能。1.3.2分组交换协议 分组交换协议是指将大数据分割为一个个叫做包的较小的单位进行传输的方法。计算机通信会在每一个分组中附加上源主机地址和目标主机地址。这些发送端地址、接收地址以及分组序号写入的部分称之为\"报文首部\" 。 1.4 协议由谁来制定？ 1.5 协议分层与OSI参考模型 序号 分层名称 功能 每层的功能概览 7 应用层 针对特定应用的协议 针对每个应用的协议：电子邮件协议、远程登录协议、文件传输协议。 6 表示层 设备固有数据格式和网络标准数据格式的转换 接收不同表现形式的信息，如文字流、图像、声音等 5 会话层 通信管理。负责建立和断开通信连接（数据流动的逻辑电路）。管理传输层以下的分层。 负责何时建立连接，何时断开连接以及保持多久的连接？ 4 传输层 管理两个节点之间的数据传输。负责可靠传输（确保数据被可靠的传送到目标地址）。 是否有数据丢失？ 3 网络层 地址管理与路由选择 经过哪个路由传递到目标地址？ 2 数据链路层 互连设备之间传送和识别数据帧 数据帧与比特流之间的转换 1 物理层 以“0”、”1“代表电压的高低、灯光的闪灭。界定连接器和网线的规格。 比特流与电子信号之间的切换 表示层： 表示层与表示层之间为了识别编码格式也会附加首部信息，从而将实际传输的数据转交给下一层去处理。 会话层： 会话层也像应用层或表示层那样，在其收到的数据前端附加首部或标签信息后转发给下一层。而这些首部或标签中记录着数据传输顺序的信息。 传输层 主机A确保主机B之间的通信并准备发送数据，着一个过层叫做”建立连接“。 两个主机之间爱呢创建的逻辑上的通信连接的断开与连接是传输层的主要作用。 传输层为了确保所传输的数据到达目的地址，会在通信两端的计算机之间进行确认，如果数据没有到达，它会负责重发。 网络层 网络层的作用是在网络与网络互连的环境中，将数据从发送端主机发送到接收端主机。 1.6. 七层通信流程图 1.7. 传输方式的分类 1.7.1 面向有连接型与面向无连接型 面向有连接型 面向有连接型中，在发送数据之前，需要在收发主机之间连接一条通信线路。（在通信传输之前，先打开一个连接。连接被关闭时无法发送数据） 面向无连接型 面向无连接型则不要求建立和断开连接。发送端可以在任何的时候自由发送数据。反之接收端也永远不知道之际何时从哪里接收到数据。 1.7.2 电路交换与分组交换 网路通信方式大致分为两种方式：电路交换（过去的电话线路）以及分组交换（较新的，TCP/IP采用）。 分组交换 在分组交换的处理过程是：发送端计算机将数据分组发送给路由器，路由器收到这些分组数据以后，缓存到自己的缓冲区，然后在发送给目标计算机。 在分组交换中，计算机与路由器之间以及路由器与路由器之间通常只有一条通信线路。 1.7.3 根据接收端数量分类 在网络通信当中，根据目标地址的个数及其后续的行为对通信进行分类如下： 单播 广播 多播 任播 1.8 地址 地址的层次型 mac地址和IP地址在标识一个通信主体时虽然都具有唯一性，但是只有IP地址具有层次型。 Mac地址----mac地址是由设备制造商针对每块网卡进行分别指定。可以通过制造商别号、制造商内部产品编号以及产品通用编号确保mac地址的唯一性。 IP地址是如何实现分层的？ IP地址由网络号和主机号两部分组成。即使IP地址不同，若主机号不同，网络号相同，说明他们处于同一个网段。 "},"network/TCPIP/chapter2.html":{"url":"network/TCPIP/chapter2.html","title":"7.2.2、TCPIP基础知识","keywords":"","body":"1. TCP/IP的标准化 1.1 TCP/IP协议群 TCP/IP一词泛指一系列协议，因此也有时候称TCP/IP为网际协议族。包括以下协议： 应用协议 HTTP、SMTP、FTP、TELNET、SNMP 路由控制协议 RIP、OSPF、BGP 网际协议 IP、ICMP、ARP 传输协议 TCP、UDP 2. TCP/IP分层模型与通信示例 2.1 包、帧、数据报、段、消息 以上五个描述词都用来表述数据单位，大致区分如下： 包：是全能性术语。 帧：用来表示数据链路层中包的单位 数据：是IP和UDP等网络层以上的分层中的单位。 段：表示TCP数据流中的信息 消息：是指应用协议中数据的单位 2.2 包首部 网络中传输的数据包由两部分组成 一部分是协议要用到的首部 另一部分是上层传递过来的数据 在数据包的首部，明确标明了协议应该如何读取数据。（包首部就想协议的脸，看到首部，就能够了解该协议必要的信息以及所需要处理的内容） 每个包首部也至少包含两个信息：一个是发送端和接收端地址，另一个是上一层的协议类型。 包的结构如下所示： 2.3 数据包接收处理 包的接收流程是发送流程的逆序过程 网络接口(以太网中网络数据连接的端口就是以太网接口)的处理 主机收到以太网包以后，首先从以太网的包首部找到MAC地址，判断是否是发给自己的包，如果不是则丢弃数据。 如果是发给自己的包，就查找以太网包首部中的类型域从而确定以太网协议传递过来的数据类型，如果以太网包首部类型域包含一个无法识别的协议类型，则丢弃数据。 IP模块的处理 IP模块接收到IP包的首部和数据部分后，先判断包首部的IP地址和自己的IP地址是否匹配，如果匹配，则可接收数据并从中查找上一层的协议，如果上一层是TCP(UDP)，则将IP包首部之后的数据传给TCP(UDP)处理,对于有路由的情况下，接受端往往不是自己的地址，此时，需要借助路由控制表，在调查应该送达的主机或路由以后再转发数据。 TCP模块处理 在TCP模块中，首先会计算一下校验和，判断数据是否破坏。然后检查是否按序号接收数据。最后检查端口号，确定具体的应用程序。 在接受完毕之后，接收端会发送一个’确认回执‘给发送端。如果这个回执信息未能到达发送端，那么发送端会认为接受端没有接收到数据而一直反复发送。 数据完整接收后，会传给段就好识别的应用程序。 应用程序处理 接收端应用程序会直接接收发送端发送的数据。通过解析数据可以获知邮件的收件人地址。 "},"network/TCPIP/chapter3.html":{"url":"network/TCPIP/chapter3.html","title":"7.2.3、数据链路","keywords":"","body":"1. 数据链路的作用 1.1 数据链路的段 数据链路的段是指一个被分割的网络 1.2 作用 IP数据模块发送和接收IP数据报； 为ARP模块发送ARP请求和接收ARP协议； 为RARP发送RARP请求和接受RARP应答。 2. 数据链路的相关技术 2.1 MAC地址 MAC地址用于识别数据链路中互连的节点。 "},"network/TCPIP/chapter4.html":{"url":"network/TCPIP/chapter4.html","title":"7.2.4、IP协议","keywords":"","body":"1. IP基础知识 IP大致分为三大作用模块，他们是IP寻址、路由、以及分包和组包 1.1 IP地址属于网络层地址 在计算机通信中，为了识别通信对端，必须要有一个类似于地址的识别码进行标识。作为网络层的IP，也有这种地址信息。一般叫做IP地址。 1.2 路由控制 路由控制是指将分组数据发送到最终目标地址的功能。即使网络非常复杂，也可以通过路由控制确定到达目标地址的通路。 一个数据包之所以能够成功地达到目的地址，全靠路由控制。 一跳(Hop)： Hop译为中文叫“跳”。它是指网络中的一个区间。IP包正是在网络中一个跳间被转发。因此IP路由也叫做多跳路由。在每一个区间内决定着包在下一跳被转发的路径。 如图所示： 1.3 数据链路的抽象化 ​ MTU的值在以太网中是1500字节，在FDDI中是4352字节，而ATM则为9180字节。IP的上一层可能会传输比这些MTU更多字节的数据，因此必须在线路上传送比包长还要小的MTU。 为了解决这个问题，IP进行分片处理(IP)，顾名思义，所谓分片处理是指，将较大的IP包分成多个较小的IP包。分片的包到了目标地址后会在被组合起来传给上一层。 1.3 IP属于面向无连接型 IP面型无连接。即在发包之前，不需要建立与对端目标地址之间的连接。上层如果需要发送给IP的数据，该数据就会立即被压缩成IP包发送出去。 IP为什么要采用面向无连接方式？ 为了简化和提速 1.4 IP地址基础知识 IP地址(IPv4地址)由32为正整数表示 1.4.1 IP地址由网路和主机两部分标识组成 如下图所示： 1.4.2 IP地址的转换（子网掩码，网络地址） "},"network/TCPIP/chapter5.html":{"url":"network/TCPIP/chapter5.html","title":"7.2.5、IP协议相关技术","keywords":"","body":"IP协议相关技术 1 DNS DNS叫做根域名服务器。它对DNS的检索起重要作用。 访问如图所示： 如果要新增或修改一个类似jp或者org的域名，在根域名服务器中进行追加或变更。 有了IP地址为什么还需要MAC地址？ 信息传递时候，需要知道的其实是两个地址：终点地址、下一跳的地址。IP地址本质上是终点地址，它在跳过路由器的时候不会改变，而MAC地址则是下一跳的地址，每跳过一次路由器都会改变。这就是为什么还要用MAC地址的原因之一，它起到了记录下一跳的信息的作用。 网络体系结构的分层模型：用MAC地址和IP地址两个地址，用于分别表示物理地址和逻辑地址是有好处的。这样分层可以使网络层与数据链路层的协议更灵活地替换。 "},"os/readme.html":{"url":"os/readme.html","title":"第八部分 操作系统","keywords":"","body":""},"os/basic/readme.html":{"url":"os/basic/readme.html","title":"8.1、操作系统基础","keywords":"","body":""},"os/basic/op_basic.html":{"url":"os/basic/op_basic.html","title":"8.1.1 操作系统基础","keywords":"","body":"1. IO常用模型的介绍 1.1 常用的四种IO模型 同步阻塞IO(Blocking IO): 传统的IO模型 同步非阻塞IO(Non-blocking IO):默认创建的socket都是阻塞的，非阻塞IO要求socket被设置为NONBLOCK。 IO多路复用(IO Multiplexing): 即经典的Reactor设计模式，有时也称为异步阻塞IO，Java中的Selector和linux中的epoll都是这种模型。 异步IO(AIO: Asynchronous IO):即经典的Proactor设计模式，也称为异步非阻塞IO。 同步与异步的区别： 同步与异步描述的是用户线程与内核的交互方式 同步：同步是指用户线程发起IO请求后需要等待或者轮询内核IO操作完成后才能继续执行。 异步：异步是指用户线程发起IO请求后仍继续执行，当内核IO操作完成后会通知用户线程。 阻塞与非阻塞的区别 阻塞与非阻塞描述的是用户线程调用IO的方式 阻塞是指IO操作需要彻底完成后才返回到用户空间 非阻塞是指IO操作被调用后立即返回一份状态值，无需IO操作彻底完成。 1.2 同步阻塞IO 同步阻塞IO是最简单的IO模型，用户在内核中进行操作时候被阻塞，如下图琐事 1.3 同步非阻塞IO 同步非阻塞IO是在同步阻塞IO的基础上。将socket设置为NONBLOCK。这样用户在发起IO请求的时候可以立即返回。 1.4 异步阻塞IO IO多路复用模型是建立在内核提供的多路分离函数select基础之上的，使用select函数可以避免同步非阻塞IO模型中轮询等待的问题。 用户首先将需要进行IO操作的socket添加到select中，然会阻塞等待select系统调用返回，当数据到达时，socket被激活。select函数返回。用户线程正式发起read请求，读取数据并执行。 1.5 异步非阻塞IO 异步IO使用的是Proactor设计模式实现这一机制。 2. Reactor模式与Proactor模式 2.1 Reactor模式 Reactor对应的类图如图所示，Reactor模式又叫反应器或反应堆，即实现注册描述以及事件的处理器。如图所示： Reactor模式的典型启动过程如下所示： 创建Rector 注册事件处理器 调用事件多路分发器进入无限事件循环 当操作系统通知描述符状态就绪的时候，事件多路分发器找出并调用此描述符注册的事件处理器。 Reactor模式的优点： 实现相对简单，相对于耗时短的处理高效 操作系统可以在多个事件源上等待，并且避免了多线程编程相关的性能开销和编程的复杂性。 事件的串行化对应用是透明的，可以顺序的同步执行不加锁 事务分离，将与应用无关的多路分解和分配机制和与应用相关的回调函数分离开 Reactor模式的缺点 Reactor处理耗时长的操作（如文件I/O）会造成事件分发的阻塞，影响到后续事件的处理。 因此涉及到文件I/O相关的操作，需要使用异步I/O，即使用Proactor模式效果更佳。 2.2 Proactor模式 Proactor模式又叫前摄器或主动器模式，如下图所示： 运行流程如下所示： Initiator主动调用Asynchronous Operation Processor发起异步I/O操作， 记录异步操作的参数和函数地址放入完成事件队列（Completion Event Queue）中 Proactor循环检测异步事件是否完成。如果完成则从完成事件队列中取出回调函数完成回调。 "},"os/linux/readme.html":{"url":"os/linux/readme.html","title":"8.2、操作系统","keywords":"","body":""},"os/linux/linux_command.html":{"url":"os/linux/linux_command.html","title":"8.2.1、linux命令","keywords":"","body":"linux中常用的命令 1. Crontab的格式 第一列表示分钟： 1~59 第二列小时：1~23 第三列表示日：1~31 第四列表示月：1~12 第五列表示星期：0~6（0表示星期天） 第六列表示要运行的命令 格式： 分 时 日 月 星期 运行的命令 30 21 * * * /usr/local/apache/bin/apachectl restart 上面的例子表示每晚的21:30重启apache 45 4 1,10,22 * * /usr/local/apache/bin/apachectl restart 上面的例子表示每月1、10、22日的4 : 45重启apache 0,30 18-23 * * * /usr/local/apache/bin/apachectl restart 上面的例子表示在每天18 : 00至23 : 00之间每隔30分钟重启apache 0 */1 * * * /usr/local/apache/bin/apachectl restart 每一小时重启apache 0 23-7/1 * * * /usr/local/apache/bin/apachectl restart 晚上11点到早上7点之间，每隔一小时重启apache 0 11 4 * mon-wed /usr/local/apache/bin/apachectl restart 每月的4号与每周一到周三的11点重启apache 0 4 1 jan * /usr/local/apache/bin/apachectl restart 一月一号的4点重启apache 0 6 */2 * * /command 看到这个我们如果理解成每xx执行就是，每两天的6点钟执行命令。在这里的范围是1-31，/2表示任务在奇数天执行，那么在1、3、5、7、8、10、12月，月末最后一天执行后，紧接着第二天仍然后执行，那这就不是每2天执行一次。 2. Centos开放80端口 命令如下所示： firewall-cmd --zone=public --add-port=80/tcp --permanent 当执行以上命令的时候，如果出现了success表明添加成功 命令含义： --zone # 作用域 --add-port=80/tcp # 添加端口，格式为：端口/通讯协议 --permanent # 永久生效，没有此参数重启后失效 接着重启防火墙 systemctl restart firewall.service 3. 如何让连接新主机时，不进行公钥确认 在首次连接服务器的时候， 会弹出公钥确认的提示，会导致任务失败。SSH客户端的StrictHostKeyChecking配置指令，可以实现当第一次连接服务器时，自动接收新的公钥。只需要修改/etc/ssh/ssh_config文件，包含下列句子： Host localhost StrictHostKeyChecking no Host 0.0.0.0 StrictHostKeyChecking no # 主机名以hadoop-*开头不用检查ssh公钥 在/etc/ssh/ssh_config 文件 Host hadoop-mango-* StrictHostKeyChecking no UserKnownHostsFile=/dev/null # 防止远程主机公钥改变导致 SSH 连接失败 ​ "},"os/linux/ubtuntu_command.html":{"url":"os/linux/ubtuntu_command.html","title":"8.2.1、ubuntu命令","keywords":"","body":"Ubuntu常见的命令 1. 第一次使用root设置密码 sudo passwd root 2.ssh的安装 sudo apt-get install openssh-server 重启ssh命令： sudo /etc/init.d/ssh resart 查看ssh是否启动 ps -e | grep ssh ssh命令 ssh-keygen -t rsa 3.设置静态IP 在对应的/etc/network/interfaces中添加如下代码 auto eth0 iface eth0 inet static address 192.168.0.117 gateway 192.168.0.1 #这个地址你要确认下 网关是不是这个地址 netmask 255.255.255.0 network 192.168.0.0 broadcast 192.168.0.255 最后重启网卡 *sudo /etc/init.d/network restart 4.端口号查询的相关命令 netstat -a 查看已经连接的服务端口 netstat -ap查看所有的端口 netstat -ap|grep 8080 lsof -i:8888查看8888端口 netstat -tap|grep mysql 查看mysql端口已经连接 "},"collaborationTools/readme.html":{"url":"collaborationTools/readme.html","title":"第九部分 协作工具","keywords":"","body":"介绍关于git、maven等工具常见的问题 "},"collaborationTools/git/git_basic_command.html":{"url":"collaborationTools/git/git_basic_command.html","title":"9.1.1、git基础命令","keywords":"","body":"git中常用的命令 1. 分支 查看远程分支 git branch -a 查看本地分支 git branch 2. git pull origin 与git fetch的区别？ git pull 相当于从远程获取最新版本并且merge到本地 git pull origin master（相当于git fetch和git merge) git fetch 相当于是从远程获取最新到本地，不会自动merge git fetch origin git merge origin/master git fetch操作包含了两个关键的步骤： 创建并且更新所有的远程分支的本地分支 设置当前分支的FETCH_HEAD为远程服务器的分支 git fetch origin branch1：branch2 首先执行上面的fetch操作 使用远程branch1分支在本地创建branch2（不会切换到该分支） 如果本地不存在branch2分支，则会自动创建一个新的branch2分支。 如果本地分支存在，并且是“fast forward”，则会合并两个分支，否则，会阻止以上操作 git fetch origin：branch2相当于git fetch origin master：branch2 3. git删除已经add的文件 使用git rm --cached “文件路径”，该命令将不会删除物理文件，仅仅会将该文件从缓存中删除 使用git rm --f “文件路径”，不仅将该文件从缓存中删除，还会将物理文件删除 tips： git reset HEAD ：清空版本库内容暂存区（慎用） git rm --cached \"文件\"：只是将特定文件从暂存区删除 4. git撤销提交 先使用git log查看commit日志，提交的commit的哈希值 使用命令 git reset --hard commit_id 进行回退 5. git缓存当前工作 git stash 可以用来缓存当前正在进行的工作，比如想pull最新代码的时候，又不想加新的commit，这时候就可以缓存当前工作。 git stash do some work git stash pop 当你多次使用git stash的时候， 你可以使用git stash list打印当前git栈信息，找到对应的版本号就可以了，git stash apply stash@{1} 6. git合并commit 可以使用git rebase -i commitid 以及使用git commit --fixup commitid git commit --fixup: 提交 git commit --fixup 54321 开发工作完成后，待推送/评审的提交中出现大量的包含“fixup!”前缀的提交该如何处理呢？ 如果你执行过一次下面的命令，即针对错误提交 54321 及其后面所有提交执行交互式变基（注意其中的 --autosquash 参数），你就会惊叹 Git 设计的是这么巧妙： git rebase -i --autosquash 54321^ ​ 7. 撤销对某一个文件的修改 场景：修改了a、b文件为列，假设需要撤销文件a的修改，则修改后的两个文件： 如果没有被git add到索引区 git checkout a便可以撤销对文件的修改 如果被git add到索引区，但没有做git commit提交 使用git reset将a从索引区移除（但是会保留在工作区） git reset HEAD a 撤销工作区文件a的修改 git checkout a 如果被提交了，则需要先回退当前提交到工作区，然后撤销文件a的修改 回退当前提交到工作区 git reset HEAD^ 撤销工作区中文件a的修改 git checkout a 8. git回退版本，删除commit git reset有三种命令方式：分别为: git reset --mixed: 此为默认方式，不带任何参数，即使用这种方式，它回退对应的commit和index（索引）中的信息 git reset --soft:回退某个版本，只回退commit信息，不会回退索引(index)，如果还需要提交，则直接commit即可。 git reset --hard:彻底回退到某个版本，本地源码也会变为上一个版本的内容。 相应的示列： git reset HEAD^ 回退所有内容到上一个版本 git reset HEAD^ a.py 回退a.py这个文件的版本到上一个版本 git reset –-soft HEAD~3 向前回退到第3个版本 git reset –-hard origin/master 将本地的状态回退到和远程的一样 it reset 057d 回退到某个版本 git revert HEAD 回退到上一次提交的状态，按照某一次的commit完全反向的进行一次commit 9. git向多个远程仓库push？ 向本地git仓库添加对应的远程仓库地址，并且为远程地址命名 git remote add gitee git@gitee.com:daiqiaobing/mango-blog.git git remote add origin git@gitee.com:daiqiaobing/mango-blog.git git push origin dlm git push gitee dlm 10. git修改commit中的提交说明 git commit --amend "},"collaborationTools/git/git_basic.html":{"url":"collaborationTools/git/git_basic.html","title":"9.1.2、git基础知识","keywords":"","body":"1.Git对象类型 git中存放对象库里面的对象只有四种：块（blob）、目录树（tree）、提交（commit）和标签（tag）。这四种原子对象构成Git高层数据结构的基础。 块（blob） 文件的每一个版本表示为一个块。blob是“二进制大对象”的缩写。一个blob被视为一个黑盒。一个blob保存一个文件的数据，但不包含任何关于这个文件的元数据，甚至连文件名也没有。 目录树（tree） 一个目录树对象代表一层目录信息。它记录blob标识符、路径和在一个目录里所有文件的一些元数据。它也可以递归引用其他目录树或子树对象，从而建立一个包含文件和子目录里所有文件的元数据。 提交（commit） 一个提交对象保存版本库每一次变化的元数据，包括作者、提交者、提交日期和日志消息。每一个提交对象指向一个目录树对象，这个目录树对象在一张完整的快照中捕获提交时候的版本库的状态。最初的提交或者根提交是没有父提交的。大多数情况下都只有一个父提交。 标签（tag） 一个标签对象分配一个任意的且可读的名字给一个特定的对象，通常是一个提交的对象。git也会把对象压缩并存储在打包文件中，这些文件也在对象库中。 2.索引 索引介绍 索引是一个临时的、动态的二进制文件，它描述的是整个版本库的目录结构。更确定的说，索引捕获项目在某一个时刻的整体结构的一个版本。项目的状态可以是一个提交和一颗目录树表示，可以是来自项目历史中的任意的时刻，或者是你正在开发的未来的状态。 索引的好处 索引使得开发的推进与提交的变更之间能够分离开来。 工作原理 通过执行git命令在索引中暂存（stage）变更。变更通常是添加、删除或者编辑某个文件或者某些文件。索引会记录和保存这些变更，保障他们的安全直到你准备好提交了。还可以删除或者替换索引中的变更。 3.可寻址内容名称 git对象库被组织及实现成一个内容寻址的存储系统。具体而言，对象中的每一个对象都有一个唯一的名称，这个名称的内容应用SHA1得到SHA1散裂值。 全局唯一标识符 SHA散列计算的一个重要特征是不管内容在哪里，它同样的内容始终产生同样的ID。换言之，在不同的目录里甚至不同的机器中的相同的文件产生的sSHA1哈希ID是完全相同的。因此文件的SHA1散列ID是一种有效的去全局唯一标识符。 4.git最终内容 如果两个文件相同，无论目录是否相同，git在对象库中只会保存一份blob形式的内容副本。git仅仅根据文件内容来产生一个文件的散列码，如果文件有相同的SHA1值，他们的内容就是相同的，然后将这个blob对象存放在对象库中，并且以SHA1值做索引。如果这些文件中的一个发生了改变，git将会重新计算SHA1值，识别他们是不是同一个blob对象，然后在把这个新的blob加到对象库中。原来的blob在对象库中不发生改变。 当文件从一个版本变到另外一个版本的时候，git的内部数据库有效的存储每个文件的每个版本，而不是他们的差异。因为git使用一个文件的全部内容的散列值座位文件名，所以它必须对每个文件的完证副本进行操作。 5.打包文件 git使用的是一种叫做打包文件的更有效的存储机制。要创建一个打包文件，git首先定位内容非常相似的全部文件，然后为他们之一存存储整个内容。之后计算的相似文件的差异存储在打包文件中。 git还维护着打包文件表示每个完整文件（包括完整内容的文件和通过差异重建出来的文件）的原始blob的SHA1值。 打包文件跟对象库中其他对象存储在一起。 6. .git目录介绍 .git/objects目录用来存放对象的目录 .git/index中存放对象跟踪的文件名（存放索引）。当使用git add命令的时候，git会给每个文件创建一个对象，但它不会马上为树创建一个对象。相反，索引更新了。索引位于.git/index中，它跟踪文件的路径以及相应的blob。每次执行命令（比如：git add、git rm、git mv）的时候，git就会用新的路径名和blob信息来更新索引。 .git/hooks这个目录存放的是一些脚本，可以设置特定的git命令后触发的相应脚本，在搭建gitweb系统或其他git托管系统会经常用到hook script。 .git/info包含仓库有的一些信息 .git/logs:保存所有更新的引用记录 .git/refs:这个目录一般包括三个子文件夹，heads、remotes和tags，heads中的文件标识了项目中的各个分支指向的当前commit. .git/COMMIT_EDITMSG:保存最新的commit message，Git系统不会用到这个文件，只是给用户一个参考。 .git/config:这个是GIt仓库的配置文件 .git/description:仓库的描述信息，主要给gitweb等git托管系统使用 .git/index:这个文件就是我们前面提到的暂存区（stage），是一个二进制文件。 .git/HEAD:这个文件包含了一个档期分支（branch）的引用，通过这个文件Git可以得到下一次commit的parent。 .git/ORIG_HEAD:HEAD指针的前一个状态。 7. git merge origin dev与git merge origin/dev的区别？ git merge origin master //将origin merge 到 master 上 git merge origin/master //将origin上的master分支 merge 到当前 branch 上 "},"collaborationTools/git/git_detach.html":{"url":"collaborationTools/git/git_detach.html","title":"9.1.3、git处于游离状态","keywords":"","body":"git 处于游离的状态的解决办法 在处于游离状态的时候，使用 git status命令查看的时候，将不会看到任何的创建的本地分支 1. step1:创建一个临时分支 对应的git命令如下所示： git branch tmp fe14301 使用的创建分支的命令为：git branch 分支名 操作的ID，此时并没有切换到对应的tmp分支上去，但是tmp分支上的就跟我们刚才最后提交的一样。 2. step2：切换分支并且合并 对应的切换分支的命令为： git checkout master 切换了分支之后我们需要对合并分支，对应合并分支的命令为： git merge tmp 最后我们只需要push对应的master分支中提交的信息。 3. step3：删除刚刚创建的分支 我们创建tmp分支的时候只是起到了临时的作用，所以在最后的时候需要将其进行删除。对应的代码为： git branch -d tmp "},"collaborationTools/git/sourcetree_install.html":{"url":"collaborationTools/git/sourcetree_install.html","title":"9.1.4、sourcetree的安装","keywords":"","body":"1. sourcetree安装跳过登陆的问题 安装 SourceTree 时，需要使用atlassian授权，因为各种原因无法完成授权，现提供跳过 atlassian账号 授权方法。 安装之后，转到用户本地文件夹下的 SourceTree 目录，没有则新建： %LocalAppData%\\Atlassian\\SourceTree\\ 新建account.json文件，并且保存一下内容，内容如下所示： [ { \"$id\": \"1\", \"$type\": \"SourceTree.Api.Host.Identity.Model.IdentityAccount, SourceTree.Api.Host.Identity\", \"Authenticate\": true, \"HostInstance\": { \"$id\": \"2\", \"$type\": \"SourceTree.Host.Atlassianaccount.AtlassianAccountInstance, SourceTree.Host.AtlassianAccount\", \"Host\": { \"$id\": \"3\", \"$type\": \"SourceTree.Host.Atlassianaccount.AtlassianAccountHost, SourceTree.Host.AtlassianAccount\", \"Id\": \"atlassian account\" }, \"BaseUrl\": \"https://id.atlassian.com/\" }, \"Credentials\": { \"$id\": \"4\", \"$type\": \"SourceTree.Model.BasicAuthCredentials, SourceTree.Api.Account\", \"Username\": \"\", \"Email\": null }, \"IsDefault\": false } ] ​ "},"web/readme.html":{"url":"web/readme.html","title":"第十部分 前端","keywords":"","body":""},"web/es6/readme.html":{"url":"web/es6/readme.html","title":"10.1、ES6","keywords":"","body":""},"web/es6/es6_description.html":{"url":"web/es6/es6_description.html","title":"1、ES6的简介","keywords":"","body":"ECMAScript 6简介 1. ECMAScript和JavaScript的关系 ECMAScript是JavaScript的规格，JavaScript是ECMAScript的实践。（通常我们可以对这两个互换） 2. 转码器（Babel） Babel是一个广泛使用的ES6转码器，可以将ES6代码转换为ES5代码，从而在现有的环境中执行。这就意味着可以使用ES6的方式编写程序，又不用担心现有的环境的支持。下面就是一个列子： // 转码前 input.map(item => item + 1); // 转码后 input.map(function (item) { return item + 1; }); 配置文件.babelrc Babel的配置文件是.babelrc，存放在项目的根目录下面。使用Babel的第一步就需要配置这个文件。该文件用来设置转吗规则和插件，基本格式如下所示： { \"presets\": [], \"plugins\": [] } ​ 3. Traceur转码器 google的Traceur转码器，也可以将ES6代码转换为ES5的代码。 "},"web/es6/let_const.html":{"url":"web/es6/let_const.html","title":"2、let和const命令.md","keywords":"","body":"et和const命令 1 let命令 1.1 基本用法 ES6新增了let命令，用来声明变量。它的用法类似于var，但是let所声明的命令只有在let所在的代码块内有效。 { let a = 10; var b = 1; } a // ReferenceError: a is not defined. b // 1 for循环的计数器，适合let命令 for (let i = 0; i let声明的变量仅在块级作用域内有效 var a = []; for (let i = 0; i 不存在变量的提升 var命令会发生“变量提升”现象，即变量可以在声明之前使用，值为undefined。 在let中不能先使用后声明，否则会报错。 // var 的情况 console.log(foo); // 输出undefined var foo = 2; // let 的情况 console.log(bar); // 报错ReferenceError let bar = 2; 1.2 暂时性死区 只要块级作用域内存在let命令，它所声明的变量就绑定这个区域，不再受到外部的影响。 var tmp = 123; if (true) { tmp = 'abc'; // ReferenceError let tmp; } 在上面的代码中，存在全局变量tmp，但是块级作用域内let又声明了一个局部变量tmp。导致了后者绑定了这个块级作用域，所以在let声明变量前，对tmp赋值会报错。 ES6明确规定，如果块中存在let和const命令，这个块对这些命令声明的变量，从一开始就形成了封闭的作用域，凡事在声明之前使用这些变量都会报错。 总之，在代码块内，使用let命令声明变量之前，该变量都是不可用的。这在语法上，称为“暂时性死区”（temporal dead zone，简称 TDZ）。 1.3 不允许重复声明 let不允许在相同作用域内重复声明同一个变量。 // 报错 function () { let a = 10; var a = 1; } // 报错 function () { let a = 10; let a = 1; } 不能在函数的内部重新声明参数 function func(arg) { let arg; // 报错 } function func(arg) { { let arg; // 不报错 } } 2 块级作用域 2.1 为什么需要块级作用域 ES5只有全局作用域和函数作用域，没有块级作用域 在ES5中的代码： var tmp = new Date(); function f() { console.log(tmp); if (false) { var tmp = 'hello world'; } } f(); // undefined 上面代码的原意是，if代码块的外部使用外层的tmp变量，内部使用内层的tmp变量。但是，函数f执行后，输出结果为undefined，原因在于变量提升，导致内层的tmp变量覆盖了外层的tmp变量。 2.2 ES6的块级作用域 let实际上为JavaScript新增了块级作用域。 function f1() { let n = 5; if (true) { let n = 10; } console.log(n); // 5 } 3. const命令 3.1 基本语法 const声明一个只读的常量。一旦声明，常量的值就不能改变。 const PI = 3.1415; PI // 3.1415 PI = 3; // TypeError: Assignment to constant variable. const声明的变量不得改变值，这意味着，const一旦声明变量，就必须立即初始化，不能留到以后赋值。 const的作用域与let命令相同：只在声明所在的块级作用域内有效。 3.2 本质 const实际上保证的并不是变量的值不得该动，而是变量指向的那个内存地址不得改动。 3.3 ES6声明变量的6种方法 es5 只有两种声明变量的方法：var和function命令。在es6中，除了添加let和const命令，还有import 和 class命令，共6种方法。 4. 顶层对象属性 顶层对象，在浏览器环境指的是window对象，在Node指的是global对象。ES5之中，顶层对象的属性与全局变量是等价的。 var命令和function命令声明的全局变量，依旧是顶层对象的属性；另一方面规定，let命令、const命令、class命令声明的全局变量，不属于顶层对象的属性。 var a = 1; // 如果在Node的REPL环境，可以写成global.a // 或者采用通用方法，写成this.a window.a // 1 let b = 1; window.b // undefined 上面代码中，全局变量a由var命令声明，所以它是顶层对象的属性；全局变量b由let命令声明，所以它不是顶层对象的属性，返回undefined。 "},"web/es6/var_value.html":{"url":"web/es6/var_value.html","title":"3、变量的解构赋值","keywords":"","body":"1. 数组的解构赋值 什么是解构赋值？什么事解构？ 解构赋值可将数组的元素或对象的属性赋予给另一个变量 从数组和对象中提取值，对变量进行赋值，这被称为解构 1.1 基本用法 es6之前： let a = 1; let b = 2; let c = 3; es6之后： let [a, b, c] = [1, 2, 3]; 可以从数组中提取值，按照对应位置，对变量赋值。 let [foo, [[bar], baz]] = [1, [[2], 3]]; foo // 1 bar // 2 baz // 3 let [ , , third] = [\"foo\", \"bar\", \"baz\"]; third // \"baz\" let [x, , y] = [1, 2, 3]; x // 1 y // 3 let [head, ...tail] = [1, 2, 3, 4]; head // 1 tail // [2, 3, 4] let [x, y, ...z] = ['a']; x // \"a\" y // undefined z // [] 如果解构不成功，变量的值就等于undefined。 2. 用途 2.1 交换变量的值 let x = 1; let y = 2; [x, y] = [y, x]; 2.2 从函数返回多个值 函数只能返回一个值，如果要返回多个值，只能将它们放在数组或对象里返回。有了解构赋值，取出这些值就非常方便。 // 返回一个数组 function example() { return [1, 2, 3]; } let [a, b, c] = example(); // 返回一个对象 function example() { return { foo: 1, bar: 2 }; } let { foo, bar } = example(); 2.3 函数参数的定义 解构赋值可以方便地将一组参数与变量名对应起来。 // 参数是一组有次序的值 function f([x, y, z]) { ... } f([1, 2, 3]); // 参数是一组无次序的值 function f({x, y, z}) { ... } f({z: 3, y: 2, x: 1}); 2.4 提取JSON数据 解构赋值对提取JSON对象中的数据，尤其有用。 let jsonData = { id: 42, status: \"OK\", data: [867, 5309] }; let { id, status, data: number } = jsonData; console.log(id, status, number); // 42, \"OK\", [867, 5309] ​ 2.5 函数参数的默认值 jQuery.ajax = function (url, { async = true, beforeSend = function () {}, cache = true, complete = function () {}, crossDomain = false, global = true, // ... more config }) { // ... do stuff }; 2.6 遍历Map解构 任何部署了Iterator接口的对象，都可以用for...of循环遍历。Map结构原生支持Iterator接口，配合变量的解构赋值，获取键名和键值就非常方便。 var map = new Map(); map.set('first', 'hello'); map.set('second', 'world'); for (let [key, value] of map) { console.log(key + \" is \" + value); } // first is hello // second is world 2.7 输入模块的指定方法 加载模块时，往往需要指定输入哪些方法。解构赋值使得输入语句非常清晰。 const { SourceMapConsumer, SourceNode } = require(\"source-map\"); ​ "},"web/vue/readme.html":{"url":"web/vue/readme.html","title":"10.2、Vue","keywords":"","body":""},"web/vue/vue_study.html":{"url":"web/vue/vue_study.html","title":"1、Vue学习","keywords":"","body":"Vue学习 1. Vue实例 1.1 构造器 每个Vue.js应用都是通过构造函数Vue创建Vue的根实例启动的： var vm = new Vue({ // 选项 }) *在实例化Vue时，需要传入一个选项对象，它可以包含数据、模版、挂载元素、方法、生命周期钩子等选项。 1.2属性与方法 每个Vue实例都会代理其data对象里所有的属性 除了data属性，Vue实例还暴露了一些有用的实例属性与方法。这些属性都有前缀$，以便与代理的data属性区分。 1.3实例生命周期 每个Vue实例在被创建之前都要经过一系列的初始化过程。例如，实例需要配置数据观测、编译模版、挂载实例到DOM，然后在数据变化时更新DOM。在这个过程中，实例也会调用一些生命钩子，这就是给我们提供了执行自己定义逻辑的机会。钩子包括：mounted、updated、destoryed、created。 1.4生命周期 下面这张图展示了生命周期： "},"web/vue/vue_error.html":{"url":"web/vue/vue_error.html","title":"2、Vue错误解决","keywords":"","body":"Vue常见的错误 1. 编译格式的错误 在编译的时候会报一些格式的错误，并非语法的错误，这个时候我们就需要在编译的时候不去检查这些格式的错误，解决办法是注释掉build/webpack.base.conf.js里面的代码，如下所示： { test: /.(js|vue)$/, loader: 'eslint-loader', enforce: \"pre\", include: [resolve('src'), resolve('test')], options: { formatter: require('eslint-friendly-formatter') } }, "},"web/angular/readme.html":{"url":"web/angular/readme.html","title":"10.3、Angular","keywords":"","body":""},"web/angular/angular_study.html":{"url":"web/angular/angular_study.html","title":"1、Angular学习","keywords":"","body":"1. 模块 Angular应用是模块化的，并且Angular有自己的模块系统，它被称为Anggular模块或NgModules。 每个Angular应用至少有一个模块（根模块），习惯上命名为AppModule。 每一个模块都是一个内聚的代码专注于某一个应用领域、工作流或紧密相关的功能。 Angular模块（无论是根模块还是特性模块）都是一个带有@NgModule装饰器的类。 NgModul是一个装饰器函数，它接收一个用来描述模块属性的元数据对象。其中最重要的属性是： declarattions -- 声明本模块中拥有的视图类。Angular有三种视图类：组件、指令和管道。 exports -- declarations的子集，可用于其他模块的组件模块。 imports -- 本模块声明的组件模块需要的类所在的其他模块。 providers -- 服务的创建者，并加入全局服务列表中，可用于应用的任何部分。 bootstrap -- 指定应用的主视图（根组件），它是所有其他视图的宿主。只有根模块才能配置bootstrap属性。 代码示列（src/app/app.module.ts）： import { NgModule } from '@angular/core'; import { BrowserModule } from '@angular/platform-browser'; @NgModule({ imports: [ BrowserModule ], providers: [ Logger ], declarations: [ AppComponent ], exports: [ AppComponent ], bootstrap: [ AppComponent ] }) export class AppModule { } 我们可以通过引导模块来启动应用。在开发期间，通常在一个main.ts文件中引导AppModule，如下所示（src/main.ts）： import { platformBrowserDynamic } from '@angular/platform-browser-dynamic'; import { AppModule } from './app/app.module'; platformBrowserDynamic().bootstrapModule(AppModule); NgModules 和JavaScript模块比较 NgModule是Angular的基础特征之一。 JavaScript也有自己的模块系统，用来管理一组JavaScript对象，与Angular的模块系统完全不同且完全无关。 在JavaScript中，每一个文件都是一个模块，文件中定义的所有的对象都从属那个模块。通过export关键字，模块可以把它的某些对象声明为公共的。其它JavaScript模块可以使用import语句来访问这些公共对象。 import { NgModule } from '@angular/core'; import { AppComponent } from './app.component'; export class AppModule { } 2. Angular模块库 Angular提供了一组JavaScript模块。可以把他们看作库模块。每个Angular库的名字都带有@angular前缀。 在下列代码中从@angular/core库中导入Component装饰器： import { Component } from '@angular/core'; 3. 组件 组件负责控制屏幕上的一块区域，我们称之为视图。 我们在类中定义组件的应用逻辑，为试图提供支持。组件通过一些属性和方法组成的API与视图交互。 如下面代码所示（src/app/hero-list.component.ts）： export class HeroListComponent implements OnInit { heroes: Hero[]; selectedHero: Hero; constructor(private service: HeroService) { } ngOnInit() { this.heroes = this.service.getHeroes(); } selectHero(hero: Hero) { this.selectedHero = hero; } } 4. 模板 我们通过组件的自带的模板来定义组件视图。模板以HTML形式存在，告诉Angular如何渲染组件。 如下面代码所示（src/app/hero-list.component.html）： Hero List Pick a hero from the list 5. 元数据 元数据告诉Angular如何处理一个类。 在下列的代码中(src/app/hello-list.component.ts 元数据)： @Component({ selector: 'hero-list', templateUrl: './hero-list.component.html', providers: [ HeroService ] }) export class HeroListComponent implements OnInit { /* . . . */ } 在上述代码中，我们通过装饰器来附加元数据，在这里的装饰器把紧随其后的类标记成了组件。 @Component 装饰器的配置项包括： selector ： CSS选择器，它告诉Angular在父级HTML中查找 “”标签，创建并且插入该组件。 templateUrl ： 组件HTML模版对应的地址。 providers ： 组件所需服务的依赖注入提供商数组。这是在告诉Angular： 该组件的构造函数需要一个HeroService服务，这样组件就可以从中获取数据。 @Component里面的元数据会告诉Angular从哪里获取你为组件指定的主要的构建块。模版、元数据和组件共同描绘出这个视图。 其他的元数据装饰器用类似的方式指导Angular的行为。例如：@Injectable、@Input和@output等是一些常用的装饰器。 6. 数据绑定 Angular支持数据绑定，一种让模板的各个部分与组件的各部分相互合作的机制。我们往模板HTML中添加绑定标记，来告诉Angular如何把二者进行绑定。绑定方式有：绑定到DOM、绑定自DOM以及双向绑定。代码如下所示： 7. 指令 Angular模板是动态的。当Angular渲染他们的时，它会根据指令提供的操作对DOM进行转换。 组件是一个带模板的指令；@Component装饰器实际上就是一个@Directive装饰器。只是扩展了一些面向模板的特性。 其他类型的指令： 结构型指令：通过在DOM中添加、移除和替换元素来修改布局。如下代码所示： 属性型指令 : 修改一个现有元素的外观或行为。在模板中，他们看起来就像是标准的HTML属性。如下代码所示： 8. 服务 几乎任何东西都可以是一个服务，典型的服务就是一个类，具有专注地、明确的用途。它应该做一件特定的事情，并把它做好。 如下面代码所示： export class HeroService { private heroes: Hero[] = []; constructor( private backend: BackendService, private logger: Logger) { } getHeroes() { this.backend.getAll(Hero).then( (heroes: Hero[]) => { this.logger.log(`Fetched ${heroes.length} heroes.`); this.heroes.push(...heroes); // fill cache }); return this.heroes; } } 9. 依赖注入 依赖注入是提供类的新实例的一种方式，还负责处理好类所需的全部依赖。大多数依赖都是服务。Angular使用依赖注入来提供新组件以及组件所需的服务。 Angular通过查看构造函数的参数得知组件需要哪些服务。例如HerListComponent组件需要一盒HeroService服务： constructor(private service: HeroService) { } 当Abgular创建组件的时候，会首先为组件所需的服务请求一个注入器，注入器维护了一个服务的实例，并且添加到容器中，然后把这个服务返回给Angular。当所有的请求的服务都被解析完并且返回时，Angular会以这些服务为参数去调用组件的构造函数。这就是依赖注入。 如果注入器还没有HeroService，它怎么知道如何创建一个呢？ 我们必须先用注入器为HeroService注册一个提供商。提供上用来创建或返回服务。通常就是这个服务类本身（相当于new HeroService（））。 如下面代码所示： ```javascript providers: [ BackendService, HeroService, Logger ], @Component({ selector: 'hero-list', templateUrl: './hero-list.component.html', providers: [ HeroService ] }) ``` "},"web/angular/angular_error.html":{"url":"web/angular/angular_error.html","title":"2、Abgular错误解决","keywords":"","body":"1. 什么是#var？ 使用#开头，后面跟着name，password等字符串的叫做模板引用变量 模板引用变量通常用来引用模板中的某个DOM元素，还可以引用Angular组件或指令。 使用＃号来声明引用变量。#phone的意思是声明一个名叫phone的变量来引用元素。代码如下面所示： 1.1 模板引用变量怎么得到它的值？ 代码如下面所示： Name Submit 在上述的代码中heroForm出现了三次，heroForm 的值到是什么？ 使用heroForm 必须要先导入FormsModule,Angular就不会空值整个表单，那么它就是一个HTMLFORMElement实例。这里的heroForm实际上就是一个Angular NgForm指令的引用，因此具备了跟踪表单的每个控件的值和有效性的能力。 原声的元素没有form属性，但NgForm指令有。 Tips： 模板引用变量(#phone)和*ngFor部分看到的模板输入变量(let phone)是不同的。 2. []的作用、 的作用和数据绑定 []与()表示目标绑定 目标是DOM中的某些东西。这个目标可能是（元素|组件|指令）property[]、（元素|组件|指令的）事件()，或极少数情况下的attribute名。 Save click me 数据绑定 数据的绑定如下所示： | 数据方向 | 语法 | 绑定类型 | | --------------- | ---------------------------------------- | ------------------------------ | | 单向 从数据源到目标视图 | [target] = \"expression\" bind-target = \"expression\" | 插值表达式 Property Attribure 类样式 | | 单向 从视图目标到数据源 | (target) = \"statement\" on-target = \"statement\" | 事件 | | 双向 | [(target)] = \"expression\" bindon-target = \"expression\" | 双向 | "},"web/other/readme.html":{"url":"web/other/readme.html","title":"10.4、其他","keywords":"","body":""},"web/other/js_error.html":{"url":"web/other/js_error.html","title":"1、js常见错误","keywords":"","body":"JS常见错误汇总 1. 图片在chrome、firefox、IE中能够正常显示，而在其它浏览器中无法正确显示的问题？ 导致的情况： 图片的路径中包含有ad、advertise等关于广告的图片，firefox中的浏览器插件会屏蔽关于广告的相关信息，导致无法显示。 解决办法 更改图片对应的路径或者图片名 2. "},"web/other/webpack_item.html":{"url":"web/other/webpack_item.html","title":"2、webpack创建项目","keywords":"","body":"webpack创建项目详解 1. 项目的初始化 vue init webpack project-name(默认安装2.0版本) vue init webpack#1.0 project-name(安装1.0版本) 2. webpack的入口文件以及加载的顺序 3. 如何创建多页面项目？ 思路： 配置对应每个页面的入口，然后每个页面对应的入口文件的加载如上图所示 获取对应的文件的代码如下所示： var _fileInfo = {'dirs': {}} function _getSrcFileName(filename){ var dirName = path.dirname(filename), file = path.basename(filename); var fileNoType = path.basename(filename, path.extname(filename)); var name = '', dir = ''; while(true){ if(path.basename(dirName)=='src'|path.basename(dirName)=='.'|path.basename(dirName)=='..'){ break; } name = path.basename(dirName) +\"\\/\"+ name; dir = path.basename(dirName)+'/'+dir; dirName = path.dirname(dirName); } name = name + fileNoType; _fileInfo['dirs'][name] = {'name': name, 'dir': dir, 'filename': file}; return name; }; exports.getEntry= (globPath) => { var entries = {}, basename; glob.sync(globPath).forEach(function(entry) { basename = path.basename(entry, path.extname(entry)); var name = _getSrcFileName(entry); entries[name] = entry; }); return entries; }; exports.getFullFile = (name) =>{ var filename = ''; if(_fileInfo['dirs'][name]!=undefined){ filename = _fileInfo['dirs'][name]['dir'] + _fileInfo['dirs'][name]['filename'] } return path.resolve(publishDir+'/'+filename); }; 在config/index.js中配置如下所示： var build = { env: require('./prod.env'), assetsRoot: path.resolve(__dirname, '../dist'), assetsSubDirectory: 'static', assetsPublicPath: '/', productionSourceMap: true, productionGzip: false, productionGzipExtensions: ['js', 'css'] } var pages = pageUtils.getEntry('src/pages/**/*.html'); for (var pathname in pages) { build[pathname] = pageUtils.getFullFile(pathname); } module.exports = { dev: ... build: build // 编译的时候的配置入口文件 } ​``` 在webpack.base.conf.js中配置如下所示： var entries = pageUtils.getEntry('./src/pages/**/*.js'); if(!(process.env.NODE_ENV === 'production')){ entries['index'] = './src/main.js'; } module.exports = { context: path.resolve(__dirname, '../'), entry: entries, // 配置js的入口 ... .... ... } 在webpack.dev.conf.js中的配置如下所示： const devWebpackConfig = merge(baseWebpackConfig, { ... devServer: { ... ... plugins: [ new webpack.DefinePlugin({ 'process.env': require('../config/dev.env') }), ... // copy custom static assets new CopyWebpackPlugin([ { from: path.resolve(__dirname, '../src/assets/'), to: config.build.assetsRoot+'/assets/', ignore: ['.*'] } ]), new CopyWebpackPlugin([ { from: path.resolve(__dirname, '../static/'), to: config.build.assetsRoot+'/static/', ignore: ['.*'] } ]), ] }) module.exports = new Promise((resolve, reject) => { portfinder.basePort = process.env.PORT || config.dev.port portfinder.getPort((err, port) => { if (err) { reject(err) } else { ... resolve(devWebpackConfig) } }) }); var pages = pageUtils.getEntry('src/pages/**/*.html'); if(!process.env.NODE_ENV === 'production'){ entries['index'] = 'index.html'; } for (var pathname in pages) { // 配置生成的html文件，定义路径等 var conf = { filename: pathname+'.html', template: pages[pathname], // 模板路径 inject: true, // js插入 chunks: [pathname] }; devWebpackConfig.plugins.push(new HtmlWebpackPlugin(conf)); } ​``` ​ 4. 搭建过程中的思路 首先需要初始化项目，然后在配置对应的文件的入口 其次，在配置项目中的路由等信息 "},"other/readme.html":{"url":"other/readme.html","title":"其他","keywords":"","body":""},"other/agreement.html":{"url":"other/agreement.html","title":"1、开源协议","keywords":"","body":"开源协议的比较？ 到底在我们的项目中应该如何选择开源软件？ 常见的几种协议 GPL协议 LGPL协议 BSD协议 GPL协议 GPL协议就是一个开放源代码协议，软件的初始开发者使用GPL协议并公开软件的源程序后，后续使用软件源程序开发软件者亦应当根据GPL协议把自己编写的源程序进行公开。 LGPL协议 LGPL协议可以翻译为更宽松的GPL协议。与GPL的区别为，后者只是对LGPL软件的程序库的调用而不是包含其源代码时，相关程序无需开源。 调用和包含的区别类似在互联网网网页上对他人网页内容的引用：如果把他人的内容全部或部分复制到自己的网页上，就类似包含，如果只是贴一个他人网页的网址链接而不引用内容，就类似调用。有了这个协议，很多大公司就可以把很多自己后续开发内容的源程序隐藏起来。 BSD协议 BSD协议鼓励软件的作者公开自己后续开发的源代码，但不强求。在BSD协议项下开发的软件，原始的源程序是开放源代码的，但使用者修改以后，可以自行选择发布源程序或者二进制程序（即目标程序），当然，使用者有义务把自己原来使用的源程序与BSD协议在软件对外发布时一并发布。因为比较灵活，所以BSD深受大公司的欢迎。 常用软件使用的协议 MIT协议：Vue "},"other/token.html":{"url":"other/token.html","title":"2、Token介绍","keywords":"","body":"token在web应用中的使用 1. Token的介绍 ​ 通俗的讲，token是用户的一种凭证，需要拿到正确的用户和密码向token服务器申请才能得到，如果用户每次都使用用户名密码访问API的时候，容易泄露用户信息，带来安全隐患，所以在访问之前需要先生成token作为凭证访问API。 2. Keystone中的四中token 2.1 四种token比较 Token 类型 UUID PKI PKIZ Fernet 大小 32 Byte KB 级别 KB 级别 约 255 Byte 支持本地认证 不支持 支持 支持 不支持 Keystone 负载 大 小 小 大 存储于数据库 是 是 是 否 携带信息 无 user, catalog 等 user, catalog 等 user 等 涉及加密方式 无 非对称加密 非对称加密 对称加密(AES) 是否压缩 否 否 是 否 版本支持 D G J K 3. JWT的介绍 3.1. 使用场景 如： 当A用户关注了B用户的时候，系统发送邮件给B用户，并且附带一个链接\"点此关注A用户\"。链接的地址可以是这样的： https://your.awesome-app.com/make-friend/?from_user=B&target_user=A 上面的URL主要通过URL来描述这个当然这样做有一个弊端，那就是要求用户B用户是一定要先登录的。可不可以简化这个流程，让B用户不用登录就可以完成这个操作。JWT就允许我们做到这点。 3.2. JWT的组成 一个JWT实际上就是一个字符串，它由三部分组成：头部、荷载与签名。 荷载： 下面就是将添加好友的描述成一个json对象。其中添加了一些其他的信息。 { \"iss\": \"John Wu JWT\", \"iat\": 1441593502, \"exp\": 1441594722, \"aud\": \"www.example.com\", \"sub\": \"jrocket@example.com\", \"from_user\": \"B\", \"target_user\": \"A\" } 在这里面的前五个字段都是JWT的标准所定义的。 iss：该JWT的签发者 sub：该JWT所面向的用户 aud：该接收JWT的一方 exp(expires)：什么时候过期，是一个Unix时间戳 iat(issued at)：什么时候签发的 将json对象进行(base64编码)可以得到下面的字符串。这个字符串我们称作JWT的Payload(荷载)。 eyJpc3MiOiJKb2huIFd1IEpXVCIsImlhdCI6MTQ0MTU5MzUwMiwiZXhwIjoxNDQxNTk0NzIyLCJhdWQiOiJ3d3cuZXhhbXBsZS5jb20iLCJzdWIiOiJqcm9ja2V0QGV4YW1wbGUuY29tIiwiZnJvbV91c2VyIjoiQiIsInRhcmdldF91c2VyIjoiQSJ9 tips: Base64是一种编码，也就是说，它可以被翻译回原来的样子的。它并不是一种加密。 头部： JWT需要一个头部，头部用于描述该JWT的最基本的信息，例如，其类型以及签名所用的算法。这也可以被表示成一个json对象： { \"typ\": \"JWT\", \"alg\": \"HS256\" } 此时，我们也要对头部进行Base64编码： eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9 签名： 将荷载以及头部的编码之后的字符串都用句号. 连接在一起（头部在前）,就形成了 eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0 将上面拼接完的字符串用HS256算法进行加密，我们还需要提供一个密钥。如果使用mystar作为密钥的话，那么就可以得到我们加密后的内容。这一部分也叫做签名： rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM 最后将这一部分签名也拼接到被签名的字符串后面，我们得到了完整的JWT： eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0.rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM ​ 3.3. 签名的目的？ 在最后一步签名的过程中，实际上就是对头部以及荷载进行签名。一般而言，加密算法对于不同的输入产生的输出总是不一样的。 在服务器应用接收到JWT后，会首先对头部和荷载的内容用同一算法再次签名。那么服务器引用通过头部的alg字段指明了我们的加密算法。 如果服务器对头部和荷载采用同一种方法签名之后，计算出来的签名和接收到的签名不一样，那么就锁名这个Token被别人动过。应该拒绝Token。 3.4. JWT应用在单点登录 session与JWT的比较 session方式存储用户id，一开始用户的session只会存储在一台服务器上。对于有多个子域的站点。当登陆之后，为了让其他的子域可以获取到session，这要求我们在多态服务器中同步Session。 JWT的方式不会存在，应为用户的状态被送到了客户端。只需要设置JWT的Cookies的domain设置为顶级域名即可。 "}}